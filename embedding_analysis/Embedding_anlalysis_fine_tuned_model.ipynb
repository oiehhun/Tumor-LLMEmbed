{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyDataset import MyDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lama_embedding_path = '../llama_embedding/tumor_med_finetuned/dataset_tensor/'\n",
    "bert_embedding_path = '../bert_embedding/tumor_finetuned/dataset_tensor/'\n",
    "roberta_embedding_path = '../roberta_embedding/tumor_finetuned/dataset_tensor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset('train', lama_embedding_path, bert_embedding_path, roberta_embedding_path)\n",
    "test_data =MyDataset('test', lama_embedding_path, bert_embedding_path, roberta_embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "test_data = DataLoader(test_data, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 1.3877, -2.6445,  0.7119,  ...,  0.4238,  0.4985, -0.6724],\n",
      "         [ 0.3362, -0.6162,  0.2322,  ..., -0.0073, -0.1953, -0.5059],\n",
      "         [ 0.1300, -0.5361,  0.2517,  ...,  0.2153, -0.0950, -0.3718],\n",
      "         [ 0.0030, -0.4092,  0.0399,  ...,  0.1614, -0.1187, -0.3621],\n",
      "         [-0.0638, -0.3369,  0.0263,  ...,  0.2522, -0.1632, -0.2871]]],\n",
      "       dtype=torch.float16), tensor([[-0.0811, -0.7083,  0.8326,  ..., -0.6350,  0.9180,  0.5636]]), tensor([[-0.5352,  0.6397, -0.1189,  ..., -1.5615, -1.9301, -1.0474]]), tensor([3])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_data):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rep, b_rep, r_rep, label = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_rep.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4096]), torch.Size([1024]), torch.Size([1024]), 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_rep.squeeze().shape, b_rep.squeeze().shape, r_rep.squeeze().shape, label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reps 별 코사인 유사도 평균 구해보기\n",
    "def get_l1_distance(x1, x2):\n",
    "    return ((x1 - x2).abs()).sum()\n",
    "def get_l2_distance(x1, x2):\n",
    "    return ((x1 - x2)**2).sum()**.5\n",
    "def get_cosine_similarity(x1, x2):\n",
    "    return (x1 * x2).sum() / ((x1**2).sum()**.5 * (x2**2).sum()**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_cosine_similarity(reps_dict[0]['lama'][0].flatten() , reps_dict[0]['lama'][1].flatten()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 끼리의 코사인 유사도\n",
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in train_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i :{'lama' : [] ,'bert': [],'roberta': []} for i in range(6)}\n",
    "for idx in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "    lama_cosine = []\n",
    "    bert_cosine = []\n",
    "    roberta_cosine = []\n",
    "    for i in range(len(reps_dict[idx]['lama'])):\n",
    "        for j in range(i+1, len(reps_dict[idx]['lama'])):\n",
    "            lama_cosine.append(get_cosine_similarity(reps_dict[idx]['lama'][i].flatten() , reps_dict[idx]['lama'][j].flatten()).item())\n",
    "            bert_cosine.append(get_cosine_similarity(reps_dict[idx]['bert'][i].flatten() , reps_dict[idx]['bert'][j].flatten()).item())\n",
    "            roberta_cosine.append(get_cosine_similarity(reps_dict[idx]['roberta'][i].flatten() , reps_dict[idx]['roberta'][j].flatten()).item())\n",
    "\n",
    "    all_dict[idx]['lama'] = torch.tensor(lama_cosine)\n",
    "    all_dict[idx]['bert'] = torch.tensor(bert_cosine)\n",
    "    all_dict[idx]['roberta'] = torch.tensor(roberta_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 :\n",
      "Lama mean : 0.9099491238594055, std : 0.031666602939367294, min : 0.75048828125, max : 0.998046875\n",
      "Bert mean : 0.9927564263343811, std : 0.00888011883944273, min : 0.9261558651924133, max : 0.9999865889549255\n",
      "Roberta mean : 0.9656540751457214, std : 0.08705567568540573, min : 0.37397775053977966, max : 0.9999938011169434\n",
      "\n",
      "Label 1 :\n",
      "Lama mean : 0.8911696076393127, std : 0.042702287435531616, min : 0.7421875, max : 0.9990234375\n",
      "Bert mean : 0.9966709017753601, std : 0.0028710165061056614, min : 0.9811343550682068, max : 0.9999918937683105\n",
      "Roberta mean : 0.9827726483345032, std : 0.014596483670175076, min : 0.8483975529670715, max : 0.9997824430465698\n",
      "\n",
      "Label 2 :\n",
      "Lama mean : 0.8935725092887878, std : 0.06473805755376816, min : 0.54150390625, max : 0.9951171875\n",
      "Bert mean : 0.9953146576881409, std : 0.008820051327347755, min : 0.9241839647293091, max : 1.0000001192092896\n",
      "Roberta mean : 0.9897527098655701, std : 0.0062699466943740845, min : 0.9594651460647583, max : 0.9998767971992493\n",
      "\n",
      "Label 3 :\n",
      "Lama mean : 0.9075133204460144, std : 0.05215130373835564, min : 0.640625, max : 0.9990234375\n",
      "Bert mean : 0.9902612566947937, std : 0.013682028278708458, min : 0.8573510050773621, max : 0.9999902844429016\n",
      "Roberta mean : 0.9233803153038025, std : 0.09234721958637238, min : 0.40024492144584656, max : 0.9999734163284302\n",
      "\n",
      "Label 4 :\n",
      "Lama mean : 0.9214198589324951, std : 0.03736055642366409, min : 0.689453125, max : 0.99951171875\n",
      "Bert mean : 0.997686505317688, std : 0.003138964297249913, min : 0.9765340089797974, max : 0.9999982714653015\n",
      "Roberta mean : 0.9907273650169373, std : 0.008725536987185478, min : 0.9164097905158997, max : 0.9999611973762512\n",
      "\n",
      "Label 5 :\n",
      "Lama mean : 0.9143945574760437, std : 0.03389212489128113, min : 0.70556640625, max : 0.9990234375\n",
      "Bert mean : 0.9866918325424194, std : 0.021993299946188927, min : 0.8248568773269653, max : 0.9998867511749268\n",
      "Roberta mean : 0.945020318031311, std : 0.08781798928976059, min : 0.3872833251953125, max : 0.9998385906219482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(f'Label {i} :')\n",
    "    print(f'Lama mean : {all_dict[i][\"lama\"].mean()}, std : {all_dict[i][\"lama\"].std()}, min : {all_dict[i][\"lama\"].min()}, max : {all_dict[i][\"lama\"].max()}')\n",
    "    print(f'Bert mean : {all_dict[i][\"bert\"].mean()}, std : {all_dict[i][\"bert\"].std()}, min : {all_dict[i][\"bert\"].min()}, max : {all_dict[i][\"bert\"].max()}')\n",
    "    print(f'Roberta mean : {all_dict[i][\"roberta\"].mean()}, std : {all_dict[i][\"roberta\"].std()}, min : {all_dict[i][\"roberta\"].min()}, max : {all_dict[i][\"roberta\"].max()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in test_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i :{'lama' : [] ,'bert': [],'roberta': []} for i in range(6)}\n",
    "for idx in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "    lama_cosine = []\n",
    "    bert_cosine = []\n",
    "    roberta_cosine = []\n",
    "    for i in range(len(reps_dict[idx]['lama'])):\n",
    "        for j in range(i+1, len(reps_dict[idx]['lama'])):\n",
    "            lama_cosine.append(get_cosine_similarity(reps_dict[idx]['lama'][i].flatten() , reps_dict[idx]['lama'][j].flatten()).item())\n",
    "            bert_cosine.append(get_cosine_similarity(reps_dict[idx]['bert'][i].flatten() , reps_dict[idx]['bert'][j].flatten()).item())\n",
    "            roberta_cosine.append(get_cosine_similarity(reps_dict[idx]['roberta'][i].flatten() , reps_dict[idx]['roberta'][j].flatten()).item())\n",
    "\n",
    "    all_dict[idx]['lama'] = torch.tensor(lama_cosine)\n",
    "    all_dict[idx]['bert'] = torch.tensor(bert_cosine)\n",
    "    all_dict[idx]['roberta'] = torch.tensor(roberta_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Test Data-------------------\n",
      "Label 0 :\n",
      "Lama mean : 0.8884286880493164, std : 0.04591073468327522, min : 0.72607421875, max : 0.9990234375\n",
      "Bert mean : 0.8825313448905945, std : 0.3595038950443268, min : -0.2971953749656677, max : 0.9997621774673462\n",
      "Roberta mean : 0.9556592106819153, std : 0.05133352428674698, min : 0.7699362635612488, max : 0.999946117401123\n",
      "\n",
      "Label 1 :\n",
      "Lama mean : 0.8690539598464966, std : 0.06044686213135719, min : 0.68994140625, max : 0.9990234375\n",
      "Bert mean : 0.6866618394851685, std : 0.4628823399543762, min : -0.3245903551578522, max : 0.999981701374054\n",
      "Roberta mean : 0.6968095302581787, std : 0.39791131019592285, min : -0.018198715522885323, max : 0.9996711015701294\n",
      "\n",
      "Label 2 :\n",
      "Lama mean : 0.8845657110214233, std : 0.053146786987781525, min : 0.76025390625, max : 0.99609375\n",
      "Bert mean : 0.9619156122207642, std : 0.06619256734848022, min : 0.7581995129585266, max : 0.9999444484710693\n",
      "Roberta mean : 0.984171986579895, std : 0.021882247179746628, min : 0.8971543312072754, max : 0.9998447895050049\n",
      "\n",
      "Label 3 :\n",
      "Lama mean : 0.90506511926651, std : 0.06214986369013786, min : 0.67333984375, max : 1.0\n",
      "Bert mean : 0.8803348541259766, std : 0.3041750192642212, min : -0.1790059208869934, max : 0.9999881386756897\n",
      "Roberta mean : 0.7136609554290771, std : 0.37764349579811096, min : -0.04104319587349892, max : 0.9999953508377075\n",
      "\n",
      "Label 4 :\n",
      "Lama mean : 0.9016017913818359, std : 0.07566004246473312, min : 0.62744140625, max : 0.96728515625\n",
      "Bert mean : 0.8238371014595032, std : 0.382494181394577, min : -0.11306235939264297, max : 0.9998080134391785\n",
      "Roberta mean : 0.8235276937484741, std : 0.3699018657207489, min : -0.02122327871620655, max : 0.9977568984031677\n",
      "\n",
      "Label 5 :\n",
      "Lama mean : 0.9209977984428406, std : 0.02322971075773239, min : 0.8544921875, max : 0.99365234375\n",
      "Bert mean : 0.42792582511901855, std : 0.5251755118370056, min : -0.3752881586551666, max : 0.9997733235359192\n",
      "Roberta mean : 0.5350468754768372, std : 0.46039333939552307, min : -0.08681812882423401, max : 0.9991058707237244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--------------Test Data-------------------')\n",
    "for i in range(6):\n",
    "    print(f'Label {i} :')\n",
    "    print(f'Lama mean : {all_dict[i][\"lama\"].mean()}, std : {all_dict[i][\"lama\"].std()}, min : {all_dict[i][\"lama\"].min()}, max : {all_dict[i][\"lama\"].max()}')\n",
    "    print(f'Bert mean : {all_dict[i][\"bert\"].mean()}, std : {all_dict[i][\"bert\"].std()}, min : {all_dict[i][\"bert\"].min()}, max : {all_dict[i][\"bert\"].max()}')\n",
    "    print(f'Roberta mean : {all_dict[i][\"roberta\"].mean()}, std : {all_dict[i][\"roberta\"].std()}, min : {all_dict[i][\"roberta\"].min()}, max : {all_dict[i][\"roberta\"].max()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다른 라벨들과의 코사인 유사도 비교\n",
    "## TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in train_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.8921552896499634, std : 0.03772232308983803, min : 0.72802734375, max : 0.9716796875\n",
      "Bert mean : -0.1666981279850006, std : 0.010526364669203758, min : -0.208282470703125, max : -0.12093579024076462\n",
      "Roberta mean : -0.03852460905909538, std : 0.03408439829945564, min : -0.16758498549461365, max : 0.1900651603937149\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.8926393389701843, std : 0.05133568122982979, min : 0.556640625, max : 0.97314453125\n",
      "Bert mean : -0.2327321171760559, std : 0.0077667078003287315, min : -0.2909048795700073, max : -0.19608166813850403\n",
      "Roberta mean : -0.018670227378606796, std : 0.0872267335653305, min : -0.09566497057676315, max : 0.8220071792602539\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.9025869369506836, std : 0.04167019948363304, min : 0.6494140625, max : 0.9697265625\n",
      "Bert mean : -0.18996699154376984, std : 0.011919560842216015, min : -0.24039670825004578, max : -0.13743461668491364\n",
      "Roberta mean : -0.03633812814950943, std : 0.05369073525071144, min : -0.21458128094673157, max : 0.3927105665206909\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.9054656624794006, std : 0.03756501153111458, min : 0.6875, max : 0.97265625\n",
      "Bert mean : -0.17969273030757904, std : 0.01971498876810074, min : -0.27686750888824463, max : -0.11130425333976746\n",
      "Roberta mean : 0.06374305486679077, std : 0.02806142531335354, min : -0.046891748905181885, max : 0.2275833636522293\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.9073610305786133, std : 0.03460235893726349, min : 0.69482421875, max : 0.97509765625\n",
      "Bert mean : -0.13676847517490387, std : 0.016758203506469727, min : -0.20293112099170685, max : -0.044069770723581314\n",
      "Roberta mean : 0.27591192722320557, std : 0.10707959532737732, min : -0.028748491778969765, max : 0.9394990801811218\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.8921552896499634, std : 0.03772232308983803, min : 0.72802734375, max : 0.9716796875\n",
      "Bert mean : -0.1666981279850006, std : 0.010526364669203758, min : -0.208282470703125, max : -0.12093579024076462\n",
      "Roberta mean : -0.03852460905909538, std : 0.03408439829945564, min : -0.16758498549461365, max : 0.1900651603937149\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.8797988891601562, std : 0.05515110120177269, min : 0.4990234375, max : 0.970703125\n",
      "Bert mean : -0.0738585814833641, std : 0.016620852053165436, min : -0.15159833431243896, max : -0.03180885687470436\n",
      "Roberta mean : 0.006647137459367514, std : 0.02528870292007923, min : -0.044925838708877563, max : 0.18437284231185913\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.8866947293281555, std : 0.04928889498114586, min : 0.5703125, max : 0.98583984375\n",
      "Bert mean : -0.12921379506587982, std : 0.018683701753616333, min : -0.16777624189853668, max : -0.02370145171880722\n",
      "Roberta mean : -0.018267137929797173, std : 0.034752532839775085, min : -0.1622258424758911, max : 0.15646211802959442\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.8861199617385864, std : 0.04772915691137314, min : 0.630859375, max : 0.97265625\n",
      "Bert mean : -0.3835200369358063, std : 0.011492789722979069, min : -0.4301632046699524, max : -0.33157965540885925\n",
      "Roberta mean : 0.0240237507969141, std : 0.021285761147737503, min : -0.06424067169427872, max : 0.15173859894275665\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.8897548913955688, std : 0.04302823916077614, min : 0.64404296875, max : 0.9736328125\n",
      "Bert mean : -0.09302949905395508, std : 0.04165785014629364, min : -0.16472922265529633, max : 0.19366060197353363\n",
      "Roberta mean : 0.08335035294294357, std : 0.04686318710446358, min : -0.09727919846773148, max : 0.3840734660625458\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.8926393389701843, std : 0.05133568122982979, min : 0.556640625, max : 0.97314453125\n",
      "Bert mean : -0.2327321469783783, std : 0.0077667078003287315, min : -0.2909048795700073, max : -0.19608166813850403\n",
      "Roberta mean : -0.018670227378606796, std : 0.0872267335653305, min : -0.09566497057676315, max : 0.8220071792602539\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.8797988891601562, std : 0.05515110120177269, min : 0.4990234375, max : 0.970703125\n",
      "Bert mean : -0.0738585889339447, std : 0.016620852053165436, min : -0.15159833431243896, max : -0.03180885687470436\n",
      "Roberta mean : 0.006647137925028801, std : 0.02528870292007923, min : -0.044925838708877563, max : 0.18437284231185913\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.8976013660430908, std : 0.05739015340805054, min : 0.546875, max : 0.98193359375\n",
      "Bert mean : -0.11563295125961304, std : 0.018156882375478745, min : -0.15807034075260162, max : -0.02087702974677086\n",
      "Roberta mean : 0.01534575130790472, std : 0.06373961269855499, min : -0.07898331433534622, max : 0.46439796686172485\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.9020086526870728, std : 0.054464444518089294, min : 0.5439453125, max : 0.97802734375\n",
      "Bert mean : -0.12760435044765472, std : 0.020093146711587906, min : -0.18202950060367584, max : 0.008646608330309391\n",
      "Roberta mean : 0.009704973548650742, std : 0.02990102209150791, min : -0.06237594410777092, max : 0.18110965192317963\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.8966359496116638, std : 0.05192262679338455, min : 0.546875, max : 0.9716796875\n",
      "Bert mean : -0.19343872368335724, std : 0.013579152524471283, min : -0.22535483539104462, max : -0.12208045274019241\n",
      "Roberta mean : -0.09212414175271988, std : 0.0633523091673851, min : -0.16939470171928406, max : 0.5139960050582886\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.9025869369506836, std : 0.04167019948363304, min : 0.6494140625, max : 0.9697265625\n",
      "Bert mean : -0.18996699154376984, std : 0.011919560842216015, min : -0.24039670825004578, max : -0.13743461668491364\n",
      "Roberta mean : -0.03633812814950943, std : 0.05369073525071144, min : -0.21458128094673157, max : 0.3927105665206909\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.8866947293281555, std : 0.04928889498114586, min : 0.5703125, max : 0.98583984375\n",
      "Bert mean : -0.12921379506587982, std : 0.018683701753616333, min : -0.16777624189853668, max : -0.02370145171880722\n",
      "Roberta mean : -0.018267139792442322, std : 0.034752532839775085, min : -0.1622258424758911, max : 0.15646211802959442\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.8976013660430908, std : 0.05739015340805054, min : 0.546875, max : 0.98193359375\n",
      "Bert mean : -0.11563295125961304, std : 0.018156882375478745, min : -0.15807034075260162, max : -0.02087702974677086\n",
      "Roberta mean : 0.01534575130790472, std : 0.06373961269855499, min : -0.07898331433534622, max : 0.46439796686172485\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.9100540280342102, std : 0.04377192631363869, min : 0.638671875, max : 0.98486328125\n",
      "Bert mean : -0.08077384531497955, std : 0.012684598565101624, min : -0.1213790774345398, max : -0.014056956395506859\n",
      "Roberta mean : 0.07123278081417084, std : 0.11277011036872864, min : -0.11984659731388092, max : 0.8688826560974121\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.904175341129303, std : 0.04166007414460182, min : 0.63427734375, max : 0.9755859375\n",
      "Bert mean : -0.199179545044899, std : 0.015762684866786003, min : -0.2278851866722107, max : -0.10059773176908493\n",
      "Roberta mean : 0.013862081803381443, std : 0.05543379858136177, min : -0.21620561182498932, max : 0.2467423975467682\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.9054656624794006, std : 0.03756501153111458, min : 0.6875, max : 0.97265625\n",
      "Bert mean : -0.17969271540641785, std : 0.01971498876810074, min : -0.27686750888824463, max : -0.11130425333976746\n",
      "Roberta mean : 0.06374305486679077, std : 0.02806142531335354, min : -0.046891748905181885, max : 0.2275833636522293\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.8861199617385864, std : 0.04772915691137314, min : 0.630859375, max : 0.97265625\n",
      "Bert mean : -0.3835200071334839, std : 0.011492789722979069, min : -0.4301632046699524, max : -0.33157965540885925\n",
      "Roberta mean : 0.02402375265955925, std : 0.021285761147737503, min : -0.06424067169427872, max : 0.15173859894275665\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.9020086526870728, std : 0.054464444518089294, min : 0.5439453125, max : 0.97802734375\n",
      "Bert mean : -0.12760436534881592, std : 0.020093146711587906, min : -0.18202950060367584, max : 0.008646608330309391\n",
      "Roberta mean : 0.009704974479973316, std : 0.02990102209150791, min : -0.06237594410777092, max : 0.18110965192317963\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.9100540280342102, std : 0.04377192631363869, min : 0.638671875, max : 0.98486328125\n",
      "Bert mean : -0.08077383786439896, std : 0.012684598565101624, min : -0.1213790774345398, max : -0.014056956395506859\n",
      "Roberta mean : 0.07123278081417084, std : 0.11277011036872864, min : -0.11984659731388092, max : 0.8688826560974121\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.9129637479782104, std : 0.036162033677101135, min : 0.67333984375, max : 0.9794921875\n",
      "Bert mean : -0.20215891301631927, std : 0.03873356431722641, min : -0.4562912583351135, max : -0.10840586572885513\n",
      "Roberta mean : -0.011392700485885143, std : 0.026473958045244217, min : -0.14931583404541016, max : 0.14334484934806824\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.9073610305786133, std : 0.03460235893726349, min : 0.69482421875, max : 0.97509765625\n",
      "Bert mean : -0.13676847517490387, std : 0.016758203506469727, min : -0.20293112099170685, max : -0.044069770723581314\n",
      "Roberta mean : 0.27591195702552795, std : 0.10707959532737732, min : -0.028748491778969765, max : 0.9394990801811218\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.8897548913955688, std : 0.04302823916077614, min : 0.64404296875, max : 0.9736328125\n",
      "Bert mean : -0.09302949160337448, std : 0.04165785014629364, min : -0.16472922265529633, max : 0.19366060197353363\n",
      "Roberta mean : 0.08335036039352417, std : 0.04686318710446358, min : -0.09727919846773148, max : 0.3840734660625458\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.8966359496116638, std : 0.05192262679338455, min : 0.546875, max : 0.9716796875\n",
      "Bert mean : -0.19343872368335724, std : 0.013579152524471283, min : -0.22535483539104462, max : -0.12208045274019241\n",
      "Roberta mean : -0.09212414920330048, std : 0.0633523091673851, min : -0.16939470171928406, max : 0.5139960050582886\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.904175341129303, std : 0.04166007414460182, min : 0.63427734375, max : 0.9755859375\n",
      "Bert mean : -0.19917957484722137, std : 0.015762684866786003, min : -0.2278851866722107, max : -0.10059773176908493\n",
      "Roberta mean : 0.013862081803381443, std : 0.05543379858136177, min : -0.21620561182498932, max : 0.2467423975467682\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.9129637479782104, std : 0.036162033677101135, min : 0.67333984375, max : 0.9794921875\n",
      "Bert mean : -0.20215892791748047, std : 0.03873356431722641, min : -0.4562912583351135, max : -0.10840586572885513\n",
      "Roberta mean : -0.011392699554562569, std : 0.026473958045244217, min : -0.14931583404541016, max : 0.14334484934806824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in test_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.874394953250885, std : 0.049826718866825104, min : 0.6787109375, max : 0.96533203125\n",
      "Bert mean : -0.14266011118888855, std : 0.13258406519889832, min : -0.2987886369228363, max : 0.9136795997619629\n",
      "Roberta mean : 0.05507628247141838, std : 0.19220171868801117, min : -0.08155005425214767, max : 0.8289508819580078\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.8777032494544983, std : 0.04331820085644722, min : 0.71728515625, max : 0.96142578125\n",
      "Bert mean : -0.22013546526432037, std : 0.0641045793890953, min : -0.284465491771698, max : 0.1181434914469719\n",
      "Roberta mean : -0.03148631006479263, std : 0.01759730465710163, min : -0.08271956443786621, max : 0.04119328409433365\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.8918478488922119, std : 0.051497478038072586, min : 0.6396484375, max : 0.95263671875\n",
      "Bert mean : -0.14841324090957642, std : 0.22305595874786377, min : -0.3096223771572113, max : 0.9735559821128845\n",
      "Roberta mean : 0.008408951573073864, std : 0.11687132716178894, min : -0.13296078145503998, max : 0.7164315581321716\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.8862150311470032, std : 0.06113670393824577, min : 0.595703125, max : 0.96728515625\n",
      "Bert mean : -0.17374226450920105, std : 0.041644103825092316, min : -0.28353458642959595, max : 0.07786160707473755\n",
      "Roberta mean : 0.05889064818620682, std : 0.03464774787425995, min : -0.06318297982215881, max : 0.18513426184654236\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.8987357020378113, std : 0.03569822013378143, min : 0.76416015625, max : 0.95703125\n",
      "Bert mean : -0.17347352206707, std : 0.08544764667749405, min : -0.3197597861289978, max : 0.9465936422348022\n",
      "Roberta mean : 0.240835502743721, std : 0.1960969865322113, min : -0.1757146567106247, max : 0.7915641665458679\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.874394953250885, std : 0.049826718866825104, min : 0.6787109375, max : 0.96533203125\n",
      "Bert mean : -0.14266009628772736, std : 0.13258406519889832, min : -0.2987886369228363, max : 0.9136795997619629\n",
      "Roberta mean : 0.05507627874612808, std : 0.19220171868801117, min : -0.08155005425214767, max : 0.8289508819580078\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.87040114402771, std : 0.05218801274895668, min : 0.71142578125, max : 0.9560546875\n",
      "Bert mean : -0.05186343193054199, std : 0.20709696412086487, min : -0.4008021950721741, max : 0.9917566776275635\n",
      "Roberta mean : 0.053145840764045715, std : 0.19266051054000854, min : -0.10450652241706848, max : 0.967191755771637\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.8820654153823853, std : 0.05767807736992836, min : 0.603515625, max : 0.96923828125\n",
      "Bert mean : -0.07531848549842834, std : 0.22725418210029602, min : -0.19512948393821716, max : 0.997750461101532\n",
      "Roberta mean : 0.071658194065094, std : 0.2503490149974823, min : -0.12399380654096603, max : 0.9962494969367981\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.8773868680000305, std : 0.0681958720088005, min : 0.56201171875, max : 0.95849609375\n",
      "Bert mean : -0.34318336844444275, std : 0.13537421822547913, min : -0.5188316702842712, max : 0.9617279171943665\n",
      "Roberta mean : 0.03931935504078865, std : 0.06881491839885712, min : -0.06753883510828018, max : 0.9563272595405579\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.8855646252632141, std : 0.047389958053827286, min : 0.72412109375, max : 0.96533203125\n",
      "Bert mean : -0.02648257464170456, std : 0.2990797758102417, min : -0.452262282371521, max : 0.9919337630271912\n",
      "Roberta mean : 0.1256842017173767, std : 0.20102496445178986, min : -0.10597074776887894, max : 0.9876200556755066\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.8777032494544983, std : 0.04331820085644722, min : 0.71728515625, max : 0.96142578125\n",
      "Bert mean : -0.22013548016548157, std : 0.0641045793890953, min : -0.284465491771698, max : 0.1181434914469719\n",
      "Roberta mean : -0.03148631006479263, std : 0.01759730465710163, min : -0.08271956443786621, max : 0.04119328409433365\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.87040114402771, std : 0.05218801274895668, min : 0.71142578125, max : 0.9560546875\n",
      "Bert mean : -0.05186343193054199, std : 0.20709696412086487, min : -0.4008021950721741, max : 0.9917566776275635\n",
      "Roberta mean : 0.053145840764045715, std : 0.19266051054000854, min : -0.10450652241706848, max : 0.967191755771637\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.8909749388694763, std : 0.05495569109916687, min : 0.630859375, max : 0.966796875\n",
      "Bert mean : -0.07952677458524704, std : 0.09198979288339615, min : -0.1703888475894928, max : 0.33495303988456726\n",
      "Roberta mean : 0.013209665194153786, std : 0.0697527751326561, min : -0.10787702351808548, max : 0.40821245312690735\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.8836401700973511, std : 0.06866849213838577, min : 0.6181640625, max : 0.97119140625\n",
      "Bert mean : -0.021288929507136345, std : 0.3085426390171051, min : -0.18919792771339417, max : 0.9983481764793396\n",
      "Roberta mean : 0.08204485476016998, std : 0.2721855044364929, min : -0.055391713976860046, max : 0.9954660534858704\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.8889363408088684, std : 0.04588625952601433, min : 0.76806640625, max : 0.958984375\n",
      "Bert mean : 0.028415938839316368, std : 0.41320616006851196, min : -0.2942323088645935, max : 0.9946339726448059\n",
      "Roberta mean : 0.0293334499001503, std : 0.30441415309906006, min : -0.1615443378686905, max : 0.9827514886856079\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.8918478488922119, std : 0.051497478038072586, min : 0.6396484375, max : 0.95263671875\n",
      "Bert mean : -0.14841324090957642, std : 0.22305595874786377, min : -0.3096223771572113, max : 0.9735559821128845\n",
      "Roberta mean : 0.008408951573073864, std : 0.11687132716178894, min : -0.13296078145503998, max : 0.7164315581321716\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.8820654153823853, std : 0.05767807736992836, min : 0.603515625, max : 0.96923828125\n",
      "Bert mean : -0.07531848549842834, std : 0.22725418210029602, min : -0.19512948393821716, max : 0.997750461101532\n",
      "Roberta mean : 0.0716581791639328, std : 0.2503490149974823, min : -0.12399380654096603, max : 0.9962494969367981\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.8909749388694763, std : 0.05495569109916687, min : 0.630859375, max : 0.966796875\n",
      "Bert mean : -0.07952676713466644, std : 0.09198979288339615, min : -0.1703888475894928, max : 0.33495303988456726\n",
      "Roberta mean : 0.013209667056798935, std : 0.0697527751326561, min : -0.10787702351808548, max : 0.40821245312690735\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.8997656106948853, std : 0.0669078603386879, min : 0.6337890625, max : 0.96826171875\n",
      "Bert mean : -0.09357620030641556, std : 0.06431104242801666, min : -0.36517447233200073, max : 0.21023023128509521\n",
      "Roberta mean : 0.10346400737762451, std : 0.2245309203863144, min : -0.09954153001308441, max : 0.981991708278656\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.9068759083747864, std : 0.04408756271004677, min : 0.6708984375, max : 0.96826171875\n",
      "Bert mean : -0.04590533301234245, std : 0.34482675790786743, min : -0.29041799902915955, max : 0.9927626848220825\n",
      "Roberta mean : 0.12237651646137238, std : 0.26982590556144714, min : -0.14889036118984222, max : 0.9821911454200745\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.8862150311470032, std : 0.06113670393824577, min : 0.595703125, max : 0.96728515625\n",
      "Bert mean : -0.17374230921268463, std : 0.041644103825092316, min : -0.28353458642959595, max : 0.07786160707473755\n",
      "Roberta mean : 0.05889064073562622, std : 0.03464774787425995, min : -0.06318297982215881, max : 0.18513426184654236\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.8773868680000305, std : 0.0681958720088005, min : 0.56201171875, max : 0.95849609375\n",
      "Bert mean : -0.34318339824676514, std : 0.13537421822547913, min : -0.5188316702842712, max : 0.9617279171943665\n",
      "Roberta mean : 0.03931935504078865, std : 0.06881491839885712, min : -0.06753883510828018, max : 0.9563272595405579\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.8836401700973511, std : 0.06866849213838577, min : 0.6181640625, max : 0.97119140625\n",
      "Bert mean : -0.021288929507136345, std : 0.3085426390171051, min : -0.18919792771339417, max : 0.9983481764793396\n",
      "Roberta mean : 0.08204485476016998, std : 0.2721855044364929, min : -0.055391713976860046, max : 0.9954660534858704\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.8997656106948853, std : 0.0669078603386879, min : 0.6337890625, max : 0.96826171875\n",
      "Bert mean : -0.09357620030641556, std : 0.06431104242801666, min : -0.36517447233200073, max : 0.21023023128509521\n",
      "Roberta mean : 0.10346400737762451, std : 0.2245309203863144, min : -0.09954153001308441, max : 0.981991708278656\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.9084442257881165, std : 0.055484745651483536, min : 0.64208984375, max : 0.96728515625\n",
      "Bert mean : -0.1386706829071045, std : 0.1856643706560135, min : -0.4289097785949707, max : 0.986427366733551\n",
      "Roberta mean : 0.04702417552471161, std : 0.21787522733211517, min : -0.11786077916622162, max : 0.9895791411399841\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.8987357020378113, std : 0.03569822013378143, min : 0.76416015625, max : 0.95703125\n",
      "Bert mean : -0.1734735518693924, std : 0.08544764667749405, min : -0.3197597861289978, max : 0.9465936422348022\n",
      "Roberta mean : 0.240835502743721, std : 0.1960969865322113, min : -0.1757146567106247, max : 0.7915641665458679\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.8855646252632141, std : 0.047389958053827286, min : 0.72412109375, max : 0.96533203125\n",
      "Bert mean : -0.02648257464170456, std : 0.2990797758102417, min : -0.452262282371521, max : 0.9919337630271912\n",
      "Roberta mean : 0.1256842017173767, std : 0.20102496445178986, min : -0.10597074776887894, max : 0.9876200556755066\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.8889363408088684, std : 0.04588625952601433, min : 0.76806640625, max : 0.958984375\n",
      "Bert mean : 0.028415940701961517, std : 0.41320616006851196, min : -0.2942323088645935, max : 0.9946339726448059\n",
      "Roberta mean : 0.029333453625440598, std : 0.30441415309906006, min : -0.1615443378686905, max : 0.9827514886856079\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.9068759083747864, std : 0.04408756271004677, min : 0.6708984375, max : 0.96826171875\n",
      "Bert mean : -0.045905325561761856, std : 0.34482675790786743, min : -0.29041799902915955, max : 0.9927626848220825\n",
      "Roberta mean : 0.12237651646137238, std : 0.26982590556144714, min : -0.14889036118984222, max : 0.9821911454200745\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.9084442257881165, std : 0.055484745651483536, min : 0.64208984375, max : 0.96728515625\n",
      "Bert mean : -0.1386706829071045, std : 0.1856643706560135, min : -0.4289097785949707, max : 0.986427366733551\n",
      "Roberta mean : 0.047024186700582504, std : 0.21787522733211517, min : -0.11786077916622162, max : 0.9895791411399841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
