{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyDataset import MyDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lama_embedding_path = '../llama_embedding/tumor_3.1_finetuned/dataset_tensor/'\n",
    "lama_embedding_path = '../llama_embedding/tumor_3.1_finetuned/dataset_tensor/'\n",
    "bert_embedding_path = '../bert_embedding/tumor/dataset_tensor/'\n",
    "roberta_embedding_path = '../roberta_embedding/tumor/dataset_tensor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset('train', lama_embedding_path, bert_embedding_path, roberta_embedding_path)\n",
    "test_data =MyDataset('test', lama_embedding_path, bert_embedding_path, roberta_embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "test_data = DataLoader(test_data, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.6728, -1.4694, -0.2174,  ...,  1.9978,  0.8338, -1.1240]]]), tensor([[-0.9999, -0.9987,  1.0000,  ..., -0.9999,  0.9925, -0.9919]]), tensor([[-0.2379, -0.1287, -0.0410,  ...,  0.2268, -0.2190,  0.3663]]), tensor([3])]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_data):\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rep, b_rep, r_rep, label = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4096]), torch.Size([1024]), torch.Size([1024]), 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_rep.squeeze().shape, b_rep.squeeze().shape, r_rep.squeeze().shape, label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reps 별 코사인 유사도 평균 구해보기\n",
    "def get_l1_distance(x1, x2):\n",
    "    return ((x1 - x2).abs()).sum()\n",
    "def get_l2_distance(x1, x2):\n",
    "    return ((x1 - x2)**2).sum()**.5\n",
    "def get_cosine_similarity(x1, x2):\n",
    "    return (x1 * x2).sum() / ((x1**2).sum()**.5 * (x2**2).sum()**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_cosine_similarity(reps_dict[0]['lama'][0].flatten() , reps_dict[0]['lama'][1].flatten()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label 끼리의 코사인 유사도\n",
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in train_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i :{'lama' : [] ,'bert': [],'roberta': []} for i in range(6)}\n",
    "for idx in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "    lama_cosine = []\n",
    "    bert_cosine = []\n",
    "    roberta_cosine = []\n",
    "    for i in range(len(reps_dict[idx]['lama'])):\n",
    "        for j in range(i+1, len(reps_dict[idx]['lama'])):\n",
    "            lama_cosine.append(get_cosine_similarity(reps_dict[idx]['lama'][i].flatten() , reps_dict[idx]['lama'][j].flatten()).item())\n",
    "            bert_cosine.append(get_cosine_similarity(reps_dict[idx]['bert'][i].flatten() , reps_dict[idx]['bert'][j].flatten()).item())\n",
    "            roberta_cosine.append(get_cosine_similarity(reps_dict[idx]['roberta'][i].flatten() , reps_dict[idx]['roberta'][j].flatten()).item())\n",
    "\n",
    "    all_dict[idx]['lama'] = torch.tensor(lama_cosine)\n",
    "    all_dict[idx]['bert'] = torch.tensor(bert_cosine)\n",
    "    all_dict[idx]['roberta'] = torch.tensor(roberta_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 :\n",
      "Lama mean : 0.7878373265266418, std : 0.07275228202342987, min : 0.49943384528160095, max : 0.9956824779510498\n",
      "Bert mean : 0.9868912696838379, std : 0.01531849056482315, min : 0.9046784043312073, max : 0.9999618530273438\n",
      "Roberta mean : 0.995334804058075, std : 0.002786097815260291, min : 0.9804888963699341, max : 0.9998929500579834\n",
      "\n",
      "Label 1 :\n",
      "Lama mean : 0.8334972262382507, std : 0.05799614265561104, min : 0.6394962668418884, max : 0.9911240935325623\n",
      "Bert mean : 0.9860884547233582, std : 0.019397519528865814, min : 0.8408688902854919, max : 0.9999794960021973\n",
      "Roberta mean : 0.9947881102561951, std : 0.0032459155190736055, min : 0.9727316498756409, max : 0.9999338984489441\n",
      "\n",
      "Label 2 :\n",
      "Lama mean : 0.8235480785369873, std : 0.06319207698106766, min : 0.6173321604728699, max : 0.9907570481300354\n",
      "Bert mean : 0.9774080514907837, std : 0.026064366102218628, min : 0.8276188969612122, max : 1.0000001192092896\n",
      "Roberta mean : 0.9951775670051575, std : 0.0029374866280704737, min : 0.9748624563217163, max : 0.999754011631012\n",
      "\n",
      "Label 3 :\n",
      "Lama mean : 0.8067697882652283, std : 0.06599581241607666, min : 0.5953736305236816, max : 0.9945311546325684\n",
      "Bert mean : 0.985663115978241, std : 0.016317550092935562, min : 0.894079864025116, max : 0.9999973773956299\n",
      "Roberta mean : 0.9955755472183228, std : 0.0024589828681200743, min : 0.981174111366272, max : 0.9998583793640137\n",
      "\n",
      "Label 4 :\n",
      "Lama mean : 0.8343704342842102, std : 0.04986031353473663, min : 0.5498160123825073, max : 0.9988153576850891\n",
      "Bert mean : 0.9855084419250488, std : 0.018525635823607445, min : 0.8660475611686707, max : 0.9999996423721313\n",
      "Roberta mean : 0.9960071444511414, std : 0.0021866473834961653, min : 0.9798930287361145, max : 0.9999323487281799\n",
      "\n",
      "Label 5 :\n",
      "Lama mean : 0.8219476342201233, std : 0.04462558031082153, min : 0.6308974623680115, max : 0.9943154454231262\n",
      "Bert mean : 0.9812958836555481, std : 0.02278333343565464, min : 0.8413842916488647, max : 0.9999960064888\n",
      "Roberta mean : 0.9952963590621948, std : 0.002926279790699482, min : 0.972750186920166, max : 0.9998782277107239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(f'Label {i} :')\n",
    "    print(f'Lama mean : {all_dict[i][\"lama\"].mean()}, std : {all_dict[i][\"lama\"].std()}, min : {all_dict[i][\"lama\"].min()}, max : {all_dict[i][\"lama\"].max()}')\n",
    "    print(f'Bert mean : {all_dict[i][\"bert\"].mean()}, std : {all_dict[i][\"bert\"].std()}, min : {all_dict[i][\"bert\"].min()}, max : {all_dict[i][\"bert\"].max()}')\n",
    "    print(f'Roberta mean : {all_dict[i][\"roberta\"].mean()}, std : {all_dict[i][\"roberta\"].std()}, min : {all_dict[i][\"roberta\"].min()}, max : {all_dict[i][\"roberta\"].max()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert [tensor([2.6525, 2.7510, 2.8855,  ..., 2.8181, 2.7641, 2.7405])\n tensor([2.7395, 2.8525, 2.8339,  ..., 2.8508, 2.8607, 2.8464])\n tensor([2.6740, 2.7766, 2.7359,  ..., 2.6389, 2.6475, 2.8617])\n tensor([2.7387, 2.8126, 2.8047,  ..., 2.8480, 2.8316, 2.8782])\n tensor([2.7060, 2.7691, 2.8304,  ..., 2.7397, 2.8065, 2.7115])\n tensor([2.8093, 2.8380, 2.8372,  ..., 2.8856, 2.8254, 2.8198])] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(all_dict)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 각 row의 평균, std, min, max 구하기\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmin()\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py:11693\u001b[0m, in \u001b[0;36mDataFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11685\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m  11686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11691\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11692\u001b[0m ):\n\u001b[0;32m> 11693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[1;32m  11695\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/internals/managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/internals/blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[1;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/pandas/core/nanops.py:1686\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1683\u001b[0m inferred \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(x)\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1688\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mcomplex128)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert [tensor([2.6525, 2.7510, 2.8855,  ..., 2.8181, 2.7641, 2.7405])\n tensor([2.7395, 2.8525, 2.8339,  ..., 2.8508, 2.8607, 2.8464])\n tensor([2.6740, 2.7766, 2.7359,  ..., 2.6389, 2.6475, 2.8617])\n tensor([2.7387, 2.8126, 2.8047,  ..., 2.8480, 2.8316, 2.8782])\n tensor([2.7060, 2.7691, 2.8304,  ..., 2.7397, 2.8065, 2.7115])\n tensor([2.8093, 2.8380, 2.8372,  ..., 2.8856, 2.8254, 2.8198])] to numeric"
     ]
    }
   ],
   "source": [
    "# 위 결과 excel로 저장\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lama</th>\n",
       "      <td>[tensor(0.6625), tensor(0.7649), tensor(0.8938...</td>\n",
       "      <td>[tensor(0.7471), tensor(0.8704), tensor(0.8468...</td>\n",
       "      <td>[tensor(0.7140), tensor(0.7987), tensor(0.7736...</td>\n",
       "      <td>[tensor(0.7512), tensor(0.8205), tensor(0.8128...</td>\n",
       "      <td>[tensor(0.7697), tensor(0.8288), tensor(0.8944...</td>\n",
       "      <td>[tensor(0.8866), tensor(0.8769), tensor(0.8424...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert</th>\n",
       "      <td>[tensor(0.9969), tensor(0.9901), tensor(0.9960...</td>\n",
       "      <td>[tensor(0.9965), tensor(0.9836), tensor(0.9897...</td>\n",
       "      <td>[tensor(0.9661), tensor(0.9824), tensor(0.9665...</td>\n",
       "      <td>[tensor(0.9965), tensor(0.9983), tensor(0.9969...</td>\n",
       "      <td>[tensor(0.9398), tensor(0.9459), tensor(0.9391...</td>\n",
       "      <td>[tensor(0.9249), tensor(0.9636), tensor(0.9971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roberta</th>\n",
       "      <td>[tensor(0.9931), tensor(0.9960), tensor(0.9957...</td>\n",
       "      <td>[tensor(0.9960), tensor(0.9985), tensor(0.9973...</td>\n",
       "      <td>[tensor(0.9939), tensor(0.9955), tensor(0.9958...</td>\n",
       "      <td>[tensor(0.9910), tensor(0.9938), tensor(0.9950...</td>\n",
       "      <td>[tensor(0.9965), tensor(0.9944), tensor(0.9969...</td>\n",
       "      <td>[tensor(0.9977), tensor(0.9974), tensor(0.9977...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0  \\\n",
       "lama     [tensor(0.6625), tensor(0.7649), tensor(0.8938...   \n",
       "bert     [tensor(0.9969), tensor(0.9901), tensor(0.9960...   \n",
       "roberta  [tensor(0.9931), tensor(0.9960), tensor(0.9957...   \n",
       "\n",
       "                                                         1  \\\n",
       "lama     [tensor(0.7471), tensor(0.8704), tensor(0.8468...   \n",
       "bert     [tensor(0.9965), tensor(0.9836), tensor(0.9897...   \n",
       "roberta  [tensor(0.9960), tensor(0.9985), tensor(0.9973...   \n",
       "\n",
       "                                                         2  \\\n",
       "lama     [tensor(0.7140), tensor(0.7987), tensor(0.7736...   \n",
       "bert     [tensor(0.9661), tensor(0.9824), tensor(0.9665...   \n",
       "roberta  [tensor(0.9939), tensor(0.9955), tensor(0.9958...   \n",
       "\n",
       "                                                         3  \\\n",
       "lama     [tensor(0.7512), tensor(0.8205), tensor(0.8128...   \n",
       "bert     [tensor(0.9965), tensor(0.9983), tensor(0.9969...   \n",
       "roberta  [tensor(0.9910), tensor(0.9938), tensor(0.9950...   \n",
       "\n",
       "                                                         4  \\\n",
       "lama     [tensor(0.7697), tensor(0.8288), tensor(0.8944...   \n",
       "bert     [tensor(0.9398), tensor(0.9459), tensor(0.9391...   \n",
       "roberta  [tensor(0.9965), tensor(0.9944), tensor(0.9969...   \n",
       "\n",
       "                                                         5  \n",
       "lama     [tensor(0.8866), tensor(0.8769), tensor(0.8424...  \n",
       "bert     [tensor(0.9249), tensor(0.9636), tensor(0.9971...  \n",
       "roberta  [tensor(0.9977), tensor(0.9974), tensor(0.9977...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in test_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i :{'lama' : [] ,'bert': [],'roberta': []} for i in range(6)}\n",
    "for idx in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "    lama_cosine = []\n",
    "    bert_cosine = []\n",
    "    roberta_cosine = []\n",
    "    for i in range(len(reps_dict[idx]['lama'])):\n",
    "        for j in range(i+1, len(reps_dict[idx]['lama'])):\n",
    "            lama_cosine.append(get_cosine_similarity(reps_dict[idx]['lama'][i].flatten() , reps_dict[idx]['lama'][j].flatten()).item())\n",
    "            bert_cosine.append(get_cosine_similarity(reps_dict[idx]['bert'][i].flatten() , reps_dict[idx]['bert'][j].flatten()).item())\n",
    "            roberta_cosine.append(get_cosine_similarity(reps_dict[idx]['roberta'][i].flatten() , reps_dict[idx]['roberta'][j].flatten()).item())\n",
    "\n",
    "    all_dict[idx]['lama'] = torch.tensor(lama_cosine)\n",
    "    all_dict[idx]['bert'] = torch.tensor(bert_cosine)\n",
    "    all_dict[idx]['roberta'] = torch.tensor(roberta_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------Test Data-------------------\n",
      "Label 0 :\n",
      "Lama mean : 0.779055655002594, std : 0.07247831672430038, min : 0.5458939075469971, max : 0.9934595227241516\n",
      "Bert mean : 0.9793155193328857, std : 0.023359069600701332, min : 0.8788700699806213, max : 0.999977707862854\n",
      "Roberta mean : 0.994115948677063, std : 0.0030253378208726645, min : 0.9835890531539917, max : 0.9998114705085754\n",
      "\n",
      "Label 1 :\n",
      "Lama mean : 0.7998738884925842, std : 0.07061295211315155, min : 0.6148551106452942, max : 0.989418089389801\n",
      "Bert mean : 0.9911202788352966, std : 0.010052916593849659, min : 0.9487963914871216, max : 0.9999092817306519\n",
      "Roberta mean : 0.9940482974052429, std : 0.004317734390497208, min : 0.9637802839279175, max : 0.9999279975891113\n",
      "\n",
      "Label 2 :\n",
      "Lama mean : 0.812993049621582, std : 0.060396865010261536, min : 0.6495745778083801, max : 0.9872453808784485\n",
      "Bert mean : 0.9762211441993713, std : 0.02486557327210903, min : 0.8885114192962646, max : 0.999900758266449\n",
      "Roberta mean : 0.9934955835342407, std : 0.003958583809435368, min : 0.9737697839736938, max : 0.9996423721313477\n",
      "\n",
      "Label 3 :\n",
      "Lama mean : 0.7863858938217163, std : 0.0703381821513176, min : 0.6534425020217896, max : 0.9998686909675598\n",
      "Bert mean : 0.9832460284233093, std : 0.01785743609070778, min : 0.9210867881774902, max : 0.9999714493751526\n",
      "Roberta mean : 0.9952011108398438, std : 0.0023741780314594507, min : 0.9876117706298828, max : 0.9999191164970398\n",
      "\n",
      "Label 4 :\n",
      "Lama mean : 0.820858359336853, std : 0.049982402473688126, min : 0.6585356593132019, max : 0.9202178120613098\n",
      "Bert mean : 0.9802021384239197, std : 0.021352067589759827, min : 0.9172104001045227, max : 0.9998558759689331\n",
      "Roberta mean : 0.9957461953163147, std : 0.002689114771783352, min : 0.9824594855308533, max : 0.9987560510635376\n",
      "\n",
      "Label 5 :\n",
      "Lama mean : 0.8145655393600464, std : 0.04565523564815521, min : 0.6888866424560547, max : 0.9881845712661743\n",
      "Bert mean : 0.9710221886634827, std : 0.030717313289642334, min : 0.8726951479911804, max : 0.9999870657920837\n",
      "Roberta mean : 0.9958756566047668, std : 0.002042010659351945, min : 0.9880270957946777, max : 0.9998052716255188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--------------Test Data-------------------')\n",
    "for i in range(6):\n",
    "    print(f'Label {i} :')\n",
    "    print(f'Lama mean : {all_dict[i][\"lama\"].mean()}, std : {all_dict[i][\"lama\"].std()}, min : {all_dict[i][\"lama\"].min()}, max : {all_dict[i][\"lama\"].max()}')\n",
    "    print(f'Bert mean : {all_dict[i][\"bert\"].mean()}, std : {all_dict[i][\"bert\"].std()}, min : {all_dict[i][\"bert\"].min()}, max : {all_dict[i][\"bert\"].max()}')\n",
    "    print(f'Roberta mean : {all_dict[i][\"roberta\"].mean()}, std : {all_dict[i][\"roberta\"].std()}, min : {all_dict[i][\"roberta\"].min()}, max : {all_dict[i][\"roberta\"].max()}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다른 라벨들과의 코사인 유사도 비교\n",
    "## TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in train_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.6684419512748718, std : 0.04753425717353821, min : 0.5020684599876404, max : 0.8779376745223999\n",
      "Bert mean : 0.9863342642784119, std : 0.01797829382121563, min : 0.8594829440116882, max : 0.9999076724052429\n",
      "Roberta mean : 0.9947792291641235, std : 0.0030403973069041967, min : 0.9745878577232361, max : 0.9994104504585266\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.6305508613586426, std : 0.05471551790833473, min : 0.4781194031238556, max : 0.8777139782905579\n",
      "Bert mean : 0.9821799397468567, std : 0.020543904975056648, min : 0.8548378348350525, max : 0.9998860359191895\n",
      "Roberta mean : 0.9945757389068604, std : 0.003455876838415861, min : 0.970973014831543, max : 0.9991005659103394\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.727867066860199, std : 0.062253836542367935, min : 0.47244030237197876, max : 0.8987920880317688\n",
      "Bert mean : 0.9859519004821777, std : 0.016293762251734734, min : 0.8842725157737732, max : 0.9999192953109741\n",
      "Roberta mean : 0.9951332211494446, std : 0.0028469362296164036, min : 0.9773927330970764, max : 0.9992751479148865\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.6984199285507202, std : 0.05642286688089371, min : 0.5065241456031799, max : 0.8886130452156067\n",
      "Bert mean : 0.9824275970458984, std : 0.020284833386540413, min : 0.880373477935791, max : 0.9999259114265442\n",
      "Roberta mean : 0.9948351383209229, std : 0.003177186008542776, min : 0.9713383913040161, max : 0.9993075728416443\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.7579053640365601, std : 0.055504340678453445, min : 0.5116165280342102, max : 0.9199590086936951\n",
      "Bert mean : 0.9841240048408508, std : 0.01916072517633438, min : 0.8560972809791565, max : 0.9998992681503296\n",
      "Roberta mean : 0.9950788021087646, std : 0.002999986754730344, min : 0.974146842956543, max : 0.9992503523826599\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.6684419512748718, std : 0.04753425717353821, min : 0.5020684599876404, max : 0.8779376745223999\n",
      "Bert mean : 0.9863341450691223, std : 0.01797829382121563, min : 0.8594829440116882, max : 0.9999076724052429\n",
      "Roberta mean : 0.9947792291641235, std : 0.0030403973069041967, min : 0.9745878577232361, max : 0.9994104504585266\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.7047230005264282, std : 0.05758234113454819, min : 0.5412303805351257, max : 0.910639226436615\n",
      "Bert mean : 0.9814627170562744, std : 0.02234981581568718, min : 0.8325841426849365, max : 0.9999580383300781\n",
      "Roberta mean : 0.9945162534713745, std : 0.0032008555717766285, min : 0.97086101770401, max : 0.9990213513374329\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.6308977007865906, std : 0.05386309325695038, min : 0.4673122465610504, max : 0.8571126461029053\n",
      "Bert mean : 0.9846506714820862, std : 0.019830094650387764, min : 0.8372908234596252, max : 0.9999719858169556\n",
      "Roberta mean : 0.9948412775993347, std : 0.0028652865439653397, min : 0.9754555821418762, max : 0.9994932413101196\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.6462886929512024, std : 0.045637086033821106, min : 0.5214517116546631, max : 0.8562164306640625\n",
      "Bert mean : 0.9798305630683899, std : 0.024643585085868835, min : 0.8329775333404541, max : 0.9999696612358093\n",
      "Roberta mean : 0.9946351647377014, std : 0.003138377331197262, min : 0.9696484804153442, max : 0.9989039897918701\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.740175187587738, std : 0.0526374988257885, min : 0.5535315275192261, max : 0.9175042510032654\n",
      "Bert mean : 0.9831719994544983, std : 0.021602369844913483, min : 0.837393581867218, max : 0.9999088048934937\n",
      "Roberta mean : 0.9946381449699402, std : 0.003148648189380765, min : 0.9719949960708618, max : 0.9991382360458374\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.6305508613586426, std : 0.05471551790833473, min : 0.4781194031238556, max : 0.8777139782905579\n",
      "Bert mean : 0.9821799397468567, std : 0.020543904975056648, min : 0.8548378348350525, max : 0.9998860359191895\n",
      "Roberta mean : 0.9945758581161499, std : 0.003455876838415861, min : 0.970973014831543, max : 0.9991005659103394\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.7047230005264282, std : 0.05758234113454819, min : 0.5412303805351257, max : 0.910639226436615\n",
      "Bert mean : 0.9814627170562744, std : 0.02234981581568718, min : 0.8325841426849365, max : 0.9999580383300781\n",
      "Roberta mean : 0.9945163726806641, std : 0.0032008555717766285, min : 0.97086101770401, max : 0.9990213513374329\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.670166015625, std : 0.06533458083868027, min : 0.45548078417778015, max : 0.9287359714508057\n",
      "Bert mean : 0.9812936782836914, std : 0.021976975724101067, min : 0.832487940788269, max : 0.9999439716339111\n",
      "Roberta mean : 0.9952027201652527, std : 0.0028371154330670834, min : 0.977155864238739, max : 0.9995185732841492\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.7186608910560608, std : 0.05459853261709213, min : 0.5362730026245117, max : 0.9029055833816528\n",
      "Bert mean : 0.9781262874603271, std : 0.02645411714911461, min : 0.8280180096626282, max : 0.9999974370002747\n",
      "Roberta mean : 0.995449423789978, std : 0.00263800541870296, min : 0.9770553708076477, max : 0.999159574508667\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.675419270992279, std : 0.05786080285906792, min : 0.478171169757843, max : 0.9094796776771545\n",
      "Bert mean : 0.9794750809669495, std : 0.024401560425758362, min : 0.8290318846702576, max : 0.9999397993087769\n",
      "Roberta mean : 0.9949482083320618, std : 0.0031231106258928776, min : 0.9692689180374146, max : 0.9991844892501831\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.727867066860199, std : 0.062253836542367935, min : 0.47244030237197876, max : 0.8987920880317688\n",
      "Bert mean : 0.9859519004821777, std : 0.016293762251734734, min : 0.8842725157737732, max : 0.9999192953109741\n",
      "Roberta mean : 0.9951333403587341, std : 0.0028469362296164036, min : 0.9773927330970764, max : 0.9992751479148865\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.6308977007865906, std : 0.05386309325695038, min : 0.4673122465610504, max : 0.8571126461029053\n",
      "Bert mean : 0.9846507906913757, std : 0.019830094650387764, min : 0.8372908234596252, max : 0.9999719858169556\n",
      "Roberta mean : 0.9948413968086243, std : 0.0028652865439653397, min : 0.9754555821418762, max : 0.9994932413101196\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.670166015625, std : 0.06533458083868027, min : 0.45548078417778015, max : 0.9287359714508057\n",
      "Bert mean : 0.981293797492981, std : 0.021976975724101067, min : 0.832487940788269, max : 0.9999439716339111\n",
      "Roberta mean : 0.9952027201652527, std : 0.0028371154330670834, min : 0.977155864238739, max : 0.9995185732841492\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.7539827227592468, std : 0.053364284336566925, min : 0.5496695637702942, max : 0.9528266787528992\n",
      "Bert mean : 0.9839472770690918, std : 0.018866926431655884, min : 0.8700897097587585, max : 0.9999885559082031\n",
      "Roberta mean : 0.9955841898918152, std : 0.002399881836026907, min : 0.9756360054016113, max : 0.9993054866790771\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.705312192440033, std : 0.05644126236438751, min : 0.495100200176239, max : 0.946507453918457\n",
      "Bert mean : 0.9834744930267334, std : 0.019917452707886696, min : 0.8337711095809937, max : 0.9999627470970154\n",
      "Roberta mean : 0.995231032371521, std : 0.00270122941583395, min : 0.9763767719268799, max : 0.9991820454597473\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.6984198689460754, std : 0.05642286688089371, min : 0.5065241456031799, max : 0.8886130452156067\n",
      "Bert mean : 0.9824275970458984, std : 0.020284833386540413, min : 0.880373477935791, max : 0.9999259114265442\n",
      "Roberta mean : 0.9948350787162781, std : 0.003177186008542776, min : 0.9713383913040161, max : 0.9993075728416443\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.6462886929512024, std : 0.045637086033821106, min : 0.5214517116546631, max : 0.8562164306640625\n",
      "Bert mean : 0.9798305630683899, std : 0.024643585085868835, min : 0.8329775333404541, max : 0.9999696612358093\n",
      "Roberta mean : 0.9946351647377014, std : 0.003138377331197262, min : 0.9696484804153442, max : 0.9989039897918701\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.7186608910560608, std : 0.05459853261709213, min : 0.5362730026245117, max : 0.9029055833816528\n",
      "Bert mean : 0.9781262874603271, std : 0.02645411714911461, min : 0.8280180096626282, max : 0.9999974370002747\n",
      "Roberta mean : 0.995449423789978, std : 0.00263800541870296, min : 0.9770553708076477, max : 0.999159574508667\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.7539827823638916, std : 0.053364284336566925, min : 0.5496695637702942, max : 0.9528266787528992\n",
      "Bert mean : 0.9839472770690918, std : 0.018866926431655884, min : 0.8700897097587585, max : 0.9999885559082031\n",
      "Roberta mean : 0.9955841898918152, std : 0.002399881836026907, min : 0.9756360054016113, max : 0.9993054866790771\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.707417368888855, std : 0.05751640349626541, min : 0.518134355545044, max : 0.9045288562774658\n",
      "Bert mean : 0.9807239174842834, std : 0.023474255576729774, min : 0.829436182975769, max : 0.9999704957008362\n",
      "Roberta mean : 0.9953163266181946, std : 0.0028329852502793074, min : 0.9700811505317688, max : 0.9992713332176208\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.7579053044319153, std : 0.055504340678453445, min : 0.5116165280342102, max : 0.9199590086936951\n",
      "Bert mean : 0.984123945236206, std : 0.01916072517633438, min : 0.8560972809791565, max : 0.9998992681503296\n",
      "Roberta mean : 0.9950788021087646, std : 0.002999986754730344, min : 0.974146842956543, max : 0.9992503523826599\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.7401752471923828, std : 0.0526374988257885, min : 0.5535315275192261, max : 0.9175042510032654\n",
      "Bert mean : 0.9831719994544983, std : 0.021602369844913483, min : 0.837393581867218, max : 0.9999088048934937\n",
      "Roberta mean : 0.9946381449699402, std : 0.003148648189380765, min : 0.9719949960708618, max : 0.9991382360458374\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.6754191517829895, std : 0.05786080285906792, min : 0.478171169757843, max : 0.9094796776771545\n",
      "Bert mean : 0.9794750809669495, std : 0.024401560425758362, min : 0.8290318846702576, max : 0.9999397993087769\n",
      "Roberta mean : 0.9949482083320618, std : 0.0031231106258928776, min : 0.9692689180374146, max : 0.9991844892501831\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.7053120732307434, std : 0.05644126236438751, min : 0.495100200176239, max : 0.946507453918457\n",
      "Bert mean : 0.9834745526313782, std : 0.019917452707886696, min : 0.8337711095809937, max : 0.9999627470970154\n",
      "Roberta mean : 0.995231032371521, std : 0.00270122941583395, min : 0.9763767719268799, max : 0.9991820454597473\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.7074174284934998, std : 0.05751640349626541, min : 0.518134355545044, max : 0.9045288562774658\n",
      "Bert mean : 0.9807239174842834, std : 0.023474255576729774, min : 0.829436182975769, max : 0.9999704957008362\n",
      "Roberta mean : 0.9953163266181946, std : 0.0028329852502793074, min : 0.9700811505317688, max : 0.9992713332176208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in test_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.6727877855300903, std : 0.05061781033873558, min : 0.5362988710403442, max : 0.8274257183074951\n",
      "Bert mean : 0.9854336977005005, std : 0.01720646768808365, min : 0.9064790606498718, max : 0.9998049736022949\n",
      "Roberta mean : 0.9939550757408142, std : 0.003750670701265335, min : 0.9695395827293396, max : 0.9986449480056763\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.6256682872772217, std : 0.04690054431557655, min : 0.5026456713676453, max : 0.7708511352539062\n",
      "Bert mean : 0.9785114526748657, std : 0.023559190332889557, min : 0.8749093413352966, max : 0.999830424785614\n",
      "Roberta mean : 0.9937593936920166, std : 0.0033980885054916143, min : 0.9778833389282227, max : 0.9988173842430115\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.7160433530807495, std : 0.06317172944545746, min : 0.48789769411087036, max : 0.8927400708198547\n",
      "Bert mean : 0.9812770485877991, std : 0.021685641258955002, min : 0.8784774541854858, max : 0.9998173117637634\n",
      "Roberta mean : 0.9943814873695374, std : 0.0028462272603064775, min : 0.9811992049217224, max : 0.9991781711578369\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.6817430257797241, std : 0.05502455681562424, min : 0.506808340549469, max : 0.8944714665412903\n",
      "Bert mean : 0.97779780626297, std : 0.02531265653669834, min : 0.8712374567985535, max : 0.9998878240585327\n",
      "Roberta mean : 0.9944855570793152, std : 0.002795423613861203, min : 0.9821984171867371, max : 0.9991461038589478\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.7502748370170593, std : 0.04956452548503876, min : 0.5820572376251221, max : 0.8712494969367981\n",
      "Bert mean : 0.9759315848350525, std : 0.026673534885048866, min : 0.8731300234794617, max : 0.9998658895492554\n",
      "Roberta mean : 0.9946355223655701, std : 0.002596417209133506, min : 0.982982337474823, max : 0.998644232749939\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.6727878451347351, std : 0.05061781033873558, min : 0.5362988710403442, max : 0.8274257183074951\n",
      "Bert mean : 0.98543381690979, std : 0.01720646768808365, min : 0.9064790606498718, max : 0.9998049736022949\n",
      "Roberta mean : 0.9939550757408142, std : 0.003750670701265335, min : 0.9695395827293396, max : 0.9986449480056763\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.7148640155792236, std : 0.06630896031856537, min : 0.5661444067955017, max : 0.8951765894889832\n",
      "Bert mean : 0.9836869835853577, std : 0.016397597268223763, min : 0.9193012714385986, max : 0.9997873306274414\n",
      "Roberta mean : 0.9937429428100586, std : 0.0041302647441625595, min : 0.9644387364387512, max : 0.998778223991394\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.6503151059150696, std : 0.07053184509277344, min : 0.46203088760375977, max : 0.8612426519393921\n",
      "Bert mean : 0.9872787594795227, std : 0.013720164075493813, min : 0.9248362183570862, max : 0.9998303651809692\n",
      "Roberta mean : 0.9945135712623596, std : 0.0033400668762624264, min : 0.9766751527786255, max : 0.9987953901290894\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.653721809387207, std : 0.063082255423069, min : 0.5266755819320679, max : 0.8380176424980164\n",
      "Bert mean : 0.9841026663780212, std : 0.015989765524864197, min : 0.9184595346450806, max : 0.9998691082000732\n",
      "Roberta mean : 0.9946354031562805, std : 0.0036339201033115387, min : 0.96739661693573, max : 0.9986235499382019\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.7402839064598083, std : 0.05671558529138565, min : 0.6014279127120972, max : 0.8973844647407532\n",
      "Bert mean : 0.9810793399810791, std : 0.019610842689871788, min : 0.906024694442749, max : 0.9998379945755005\n",
      "Roberta mean : 0.9947232604026794, std : 0.003249021712690592, min : 0.9778653979301453, max : 0.9985402822494507\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.6256683468818665, std : 0.04690054431557655, min : 0.5026456713676453, max : 0.7708511352539062\n",
      "Bert mean : 0.9785114526748657, std : 0.023559190332889557, min : 0.8749093413352966, max : 0.999830424785614\n",
      "Roberta mean : 0.9937593936920166, std : 0.0033980885054916143, min : 0.9778833389282227, max : 0.9988173842430115\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.7148640155792236, std : 0.06630896031856537, min : 0.5661444067955017, max : 0.8951765894889832\n",
      "Bert mean : 0.9836868643760681, std : 0.016397597268223763, min : 0.9193012714385986, max : 0.9997873306274414\n",
      "Roberta mean : 0.9937430620193481, std : 0.0041302647441625595, min : 0.9644387364387512, max : 0.998778223991394\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.6691842079162598, std : 0.0680985301733017, min : 0.4621981978416443, max : 0.8537076115608215\n",
      "Bert mean : 0.9797020554542542, std : 0.021568983793258667, min : 0.8920875787734985, max : 0.9999377131462097\n",
      "Roberta mean : 0.9942718744277954, std : 0.003319636918604374, min : 0.9775134325027466, max : 0.9986808896064758\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.70567786693573, std : 0.058600056916475296, min : 0.5493291020393372, max : 0.8657492995262146\n",
      "Bert mean : 0.9762131571769714, std : 0.02524852193892002, min : 0.8848755955696106, max : 0.9999403953552246\n",
      "Roberta mean : 0.9944411516189575, std : 0.0034593837335705757, min : 0.9757620692253113, max : 0.9988154172897339\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.6962196230888367, std : 0.06525536626577377, min : 0.5340803861618042, max : 0.8906973600387573\n",
      "Bert mean : 0.9744121432304382, std : 0.02748067118227482, min : 0.8747442960739136, max : 0.9999223947525024\n",
      "Roberta mean : 0.9944242835044861, std : 0.003201760584488511, min : 0.9792300462722778, max : 0.9988391995429993\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.7160434126853943, std : 0.06317172944545746, min : 0.48789769411087036, max : 0.8927400708198547\n",
      "Bert mean : 0.9812771677970886, std : 0.021685641258955002, min : 0.8784774541854858, max : 0.9998173117637634\n",
      "Roberta mean : 0.9943816065788269, std : 0.0028462272603064775, min : 0.9811992049217224, max : 0.9991781711578369\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.6503150463104248, std : 0.07053184509277344, min : 0.46203088760375977, max : 0.8612426519393921\n",
      "Bert mean : 0.9872786402702332, std : 0.013720164075493813, min : 0.9248362183570862, max : 0.9998303651809692\n",
      "Roberta mean : 0.9945135712623596, std : 0.0033400668762624264, min : 0.9766751527786255, max : 0.9987953901290894\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.669184148311615, std : 0.0680985301733017, min : 0.4621981978416443, max : 0.8537076115608215\n",
      "Bert mean : 0.9797020554542542, std : 0.021568983793258667, min : 0.8920875787734985, max : 0.9999377131462097\n",
      "Roberta mean : 0.9942720532417297, std : 0.003319636918604374, min : 0.9775134325027466, max : 0.9986808896064758\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.7484471797943115, std : 0.05855855718255043, min : 0.5452035069465637, max : 0.9061942100524902\n",
      "Bert mean : 0.9816817045211792, std : 0.019948618486523628, min : 0.9146487712860107, max : 0.999924898147583\n",
      "Roberta mean : 0.9953834414482117, std : 0.0026863429229706526, min : 0.9805960059165955, max : 0.9989043474197388\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.7279052138328552, std : 0.06363210082054138, min : 0.540913999080658, max : 0.9076494574546814\n",
      "Bert mean : 0.9776068925857544, std : 0.024495601654052734, min : 0.8781192898750305, max : 0.9999323487281799\n",
      "Roberta mean : 0.9953649640083313, std : 0.0021433045621961355, min : 0.9871366620063782, max : 0.9987760782241821\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.6817430257797241, std : 0.05502455681562424, min : 0.506808340549469, max : 0.8944714665412903\n",
      "Bert mean : 0.9777979254722595, std : 0.02531265653669834, min : 0.8712374567985535, max : 0.9998878240585327\n",
      "Roberta mean : 0.9944854974746704, std : 0.002795423613861203, min : 0.9821984171867371, max : 0.9991461038589478\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.653721809387207, std : 0.063082255423069, min : 0.5266755819320679, max : 0.8380176424980164\n",
      "Bert mean : 0.9841026663780212, std : 0.015989765524864197, min : 0.9184595346450806, max : 0.9998691082000732\n",
      "Roberta mean : 0.9946354031562805, std : 0.0036339201033115387, min : 0.96739661693573, max : 0.9986235499382019\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.7056779265403748, std : 0.058600056916475296, min : 0.5493291020393372, max : 0.8657492995262146\n",
      "Bert mean : 0.976213276386261, std : 0.02524852193892002, min : 0.8848755955696106, max : 0.9999403953552246\n",
      "Roberta mean : 0.994441032409668, std : 0.0034593837335705757, min : 0.9757620692253113, max : 0.9988154172897339\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.7484471797943115, std : 0.05855855718255043, min : 0.5452035069465637, max : 0.9061942100524902\n",
      "Bert mean : 0.9816817045211792, std : 0.019948618486523628, min : 0.9146487712860107, max : 0.999924898147583\n",
      "Roberta mean : 0.9953834414482117, std : 0.0026863429229706526, min : 0.9805960059165955, max : 0.9989043474197388\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.7230647802352905, std : 0.06412310898303986, min : 0.5844976305961609, max : 0.8759551048278809\n",
      "Bert mean : 0.9749372601509094, std : 0.028126247227191925, min : 0.8709779977798462, max : 0.9999578595161438\n",
      "Roberta mean : 0.9957727193832397, std : 0.002352908719331026, min : 0.9825828671455383, max : 0.998999297618866\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.7502748966217041, std : 0.04956452548503876, min : 0.5820572376251221, max : 0.8712494969367981\n",
      "Bert mean : 0.9759316444396973, std : 0.026673534885048866, min : 0.8731300234794617, max : 0.9998658895492554\n",
      "Roberta mean : 0.9946355819702148, std : 0.002596417209133506, min : 0.982982337474823, max : 0.998644232749939\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.7402837872505188, std : 0.05671558529138565, min : 0.6014279127120972, max : 0.8973844647407532\n",
      "Bert mean : 0.9810793399810791, std : 0.019610842689871788, min : 0.906024694442749, max : 0.9998379945755005\n",
      "Roberta mean : 0.9947232604026794, std : 0.003249021712690592, min : 0.9778653979301453, max : 0.9985402822494507\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.6962196230888367, std : 0.06525536626577377, min : 0.5340803861618042, max : 0.8906973600387573\n",
      "Bert mean : 0.9744120240211487, std : 0.02748067118227482, min : 0.8747442960739136, max : 0.9999223947525024\n",
      "Roberta mean : 0.9944244027137756, std : 0.003201760584488511, min : 0.9792300462722778, max : 0.9988391995429993\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.7279052734375, std : 0.06363210082054138, min : 0.540913999080658, max : 0.9076494574546814\n",
      "Bert mean : 0.9776069521903992, std : 0.024495601654052734, min : 0.8781192898750305, max : 0.9999323487281799\n",
      "Roberta mean : 0.9953649640083313, std : 0.0021433045621961355, min : 0.9871366620063782, max : 0.9987760782241821\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.7230648398399353, std : 0.06412310898303986, min : 0.5844976305961609, max : 0.8759551048278809\n",
      "Bert mean : 0.9749372601509094, std : 0.028126247227191925, min : 0.8709779977798462, max : 0.9999578595161438\n",
      "Roberta mean : 0.9957727193832397, std : 0.002352908719331026, min : 0.9825828671455383, max : 0.998999297618866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다른 라벨들과의 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in train_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.6684419512748718, std : 0.04753425717353821, min : 0.5020684599876404, max : 0.8779376745223999\n",
      "Bert mean : 0.9863342642784119, std : 0.01797829382121563, min : 0.8594829440116882, max : 0.9999076724052429\n",
      "Roberta mean : 0.9947792291641235, std : 0.0030403973069041967, min : 0.9745878577232361, max : 0.9994104504585266\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.6305508613586426, std : 0.05471551790833473, min : 0.4781194031238556, max : 0.8777139782905579\n",
      "Bert mean : 0.9821799397468567, std : 0.020543904975056648, min : 0.8548378348350525, max : 0.9998860359191895\n",
      "Roberta mean : 0.9945757389068604, std : 0.003455876838415861, min : 0.970973014831543, max : 0.9991005659103394\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.727867066860199, std : 0.062253836542367935, min : 0.47244030237197876, max : 0.8987920880317688\n",
      "Bert mean : 0.9859519004821777, std : 0.016293762251734734, min : 0.8842725157737732, max : 0.9999192953109741\n",
      "Roberta mean : 0.9951332211494446, std : 0.0028469362296164036, min : 0.9773927330970764, max : 0.9992751479148865\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.6984199285507202, std : 0.05642286688089371, min : 0.5065241456031799, max : 0.8886130452156067\n",
      "Bert mean : 0.9824275970458984, std : 0.020284833386540413, min : 0.880373477935791, max : 0.9999259114265442\n",
      "Roberta mean : 0.9948351383209229, std : 0.003177186008542776, min : 0.9713383913040161, max : 0.9993075728416443\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.7579053640365601, std : 0.055504340678453445, min : 0.5116165280342102, max : 0.9199590086936951\n",
      "Bert mean : 0.9841240048408508, std : 0.01916072517633438, min : 0.8560972809791565, max : 0.9998992681503296\n",
      "Roberta mean : 0.9950788021087646, std : 0.002999986754730344, min : 0.974146842956543, max : 0.9992503523826599\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.6684419512748718, std : 0.04753425717353821, min : 0.5020684599876404, max : 0.8779376745223999\n",
      "Bert mean : 0.9863341450691223, std : 0.01797829382121563, min : 0.8594829440116882, max : 0.9999076724052429\n",
      "Roberta mean : 0.9947792291641235, std : 0.0030403973069041967, min : 0.9745878577232361, max : 0.9994104504585266\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.7047230005264282, std : 0.05758234113454819, min : 0.5412303805351257, max : 0.910639226436615\n",
      "Bert mean : 0.9814627170562744, std : 0.02234981581568718, min : 0.8325841426849365, max : 0.9999580383300781\n",
      "Roberta mean : 0.9945162534713745, std : 0.0032008555717766285, min : 0.97086101770401, max : 0.9990213513374329\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.6308977007865906, std : 0.05386309325695038, min : 0.4673122465610504, max : 0.8571126461029053\n",
      "Bert mean : 0.9846506714820862, std : 0.019830094650387764, min : 0.8372908234596252, max : 0.9999719858169556\n",
      "Roberta mean : 0.9948412775993347, std : 0.0028652865439653397, min : 0.9754555821418762, max : 0.9994932413101196\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.6462886929512024, std : 0.045637086033821106, min : 0.5214517116546631, max : 0.8562164306640625\n",
      "Bert mean : 0.9798305630683899, std : 0.024643585085868835, min : 0.8329775333404541, max : 0.9999696612358093\n",
      "Roberta mean : 0.9946351647377014, std : 0.003138377331197262, min : 0.9696484804153442, max : 0.9989039897918701\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.740175187587738, std : 0.0526374988257885, min : 0.5535315275192261, max : 0.9175042510032654\n",
      "Bert mean : 0.9831719994544983, std : 0.021602369844913483, min : 0.837393581867218, max : 0.9999088048934937\n",
      "Roberta mean : 0.9946381449699402, std : 0.003148648189380765, min : 0.9719949960708618, max : 0.9991382360458374\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.6305508613586426, std : 0.05471551790833473, min : 0.4781194031238556, max : 0.8777139782905579\n",
      "Bert mean : 0.9821799397468567, std : 0.020543904975056648, min : 0.8548378348350525, max : 0.9998860359191895\n",
      "Roberta mean : 0.9945758581161499, std : 0.003455876838415861, min : 0.970973014831543, max : 0.9991005659103394\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.7047230005264282, std : 0.05758234113454819, min : 0.5412303805351257, max : 0.910639226436615\n",
      "Bert mean : 0.9814627170562744, std : 0.02234981581568718, min : 0.8325841426849365, max : 0.9999580383300781\n",
      "Roberta mean : 0.9945163726806641, std : 0.0032008555717766285, min : 0.97086101770401, max : 0.9990213513374329\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.670166015625, std : 0.06533458083868027, min : 0.45548078417778015, max : 0.9287359714508057\n",
      "Bert mean : 0.9812936782836914, std : 0.021976975724101067, min : 0.832487940788269, max : 0.9999439716339111\n",
      "Roberta mean : 0.9952027201652527, std : 0.0028371154330670834, min : 0.977155864238739, max : 0.9995185732841492\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.7186608910560608, std : 0.05459853261709213, min : 0.5362730026245117, max : 0.9029055833816528\n",
      "Bert mean : 0.9781262874603271, std : 0.02645411714911461, min : 0.8280180096626282, max : 0.9999974370002747\n",
      "Roberta mean : 0.995449423789978, std : 0.00263800541870296, min : 0.9770553708076477, max : 0.999159574508667\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.675419270992279, std : 0.05786080285906792, min : 0.478171169757843, max : 0.9094796776771545\n",
      "Bert mean : 0.9794750809669495, std : 0.024401560425758362, min : 0.8290318846702576, max : 0.9999397993087769\n",
      "Roberta mean : 0.9949482083320618, std : 0.0031231106258928776, min : 0.9692689180374146, max : 0.9991844892501831\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.727867066860199, std : 0.062253836542367935, min : 0.47244030237197876, max : 0.8987920880317688\n",
      "Bert mean : 0.9859519004821777, std : 0.016293762251734734, min : 0.8842725157737732, max : 0.9999192953109741\n",
      "Roberta mean : 0.9951333403587341, std : 0.0028469362296164036, min : 0.9773927330970764, max : 0.9992751479148865\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.6308977007865906, std : 0.05386309325695038, min : 0.4673122465610504, max : 0.8571126461029053\n",
      "Bert mean : 0.9846507906913757, std : 0.019830094650387764, min : 0.8372908234596252, max : 0.9999719858169556\n",
      "Roberta mean : 0.9948413968086243, std : 0.0028652865439653397, min : 0.9754555821418762, max : 0.9994932413101196\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.670166015625, std : 0.06533458083868027, min : 0.45548078417778015, max : 0.9287359714508057\n",
      "Bert mean : 0.981293797492981, std : 0.021976975724101067, min : 0.832487940788269, max : 0.9999439716339111\n",
      "Roberta mean : 0.9952027201652527, std : 0.0028371154330670834, min : 0.977155864238739, max : 0.9995185732841492\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.7539827227592468, std : 0.053364284336566925, min : 0.5496695637702942, max : 0.9528266787528992\n",
      "Bert mean : 0.9839472770690918, std : 0.018866926431655884, min : 0.8700897097587585, max : 0.9999885559082031\n",
      "Roberta mean : 0.9955841898918152, std : 0.002399881836026907, min : 0.9756360054016113, max : 0.9993054866790771\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.705312192440033, std : 0.05644126236438751, min : 0.495100200176239, max : 0.946507453918457\n",
      "Bert mean : 0.9834744930267334, std : 0.019917452707886696, min : 0.8337711095809937, max : 0.9999627470970154\n",
      "Roberta mean : 0.995231032371521, std : 0.00270122941583395, min : 0.9763767719268799, max : 0.9991820454597473\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.6984198689460754, std : 0.05642286688089371, min : 0.5065241456031799, max : 0.8886130452156067\n",
      "Bert mean : 0.9824275970458984, std : 0.020284833386540413, min : 0.880373477935791, max : 0.9999259114265442\n",
      "Roberta mean : 0.9948350787162781, std : 0.003177186008542776, min : 0.9713383913040161, max : 0.9993075728416443\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.6462886929512024, std : 0.045637086033821106, min : 0.5214517116546631, max : 0.8562164306640625\n",
      "Bert mean : 0.9798305630683899, std : 0.024643585085868835, min : 0.8329775333404541, max : 0.9999696612358093\n",
      "Roberta mean : 0.9946351647377014, std : 0.003138377331197262, min : 0.9696484804153442, max : 0.9989039897918701\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.7186608910560608, std : 0.05459853261709213, min : 0.5362730026245117, max : 0.9029055833816528\n",
      "Bert mean : 0.9781262874603271, std : 0.02645411714911461, min : 0.8280180096626282, max : 0.9999974370002747\n",
      "Roberta mean : 0.995449423789978, std : 0.00263800541870296, min : 0.9770553708076477, max : 0.999159574508667\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.7539827823638916, std : 0.053364284336566925, min : 0.5496695637702942, max : 0.9528266787528992\n",
      "Bert mean : 0.9839472770690918, std : 0.018866926431655884, min : 0.8700897097587585, max : 0.9999885559082031\n",
      "Roberta mean : 0.9955841898918152, std : 0.002399881836026907, min : 0.9756360054016113, max : 0.9993054866790771\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.707417368888855, std : 0.05751640349626541, min : 0.518134355545044, max : 0.9045288562774658\n",
      "Bert mean : 0.9807239174842834, std : 0.023474255576729774, min : 0.829436182975769, max : 0.9999704957008362\n",
      "Roberta mean : 0.9953163266181946, std : 0.0028329852502793074, min : 0.9700811505317688, max : 0.9992713332176208\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.7579053044319153, std : 0.055504340678453445, min : 0.5116165280342102, max : 0.9199590086936951\n",
      "Bert mean : 0.984123945236206, std : 0.01916072517633438, min : 0.8560972809791565, max : 0.9998992681503296\n",
      "Roberta mean : 0.9950788021087646, std : 0.002999986754730344, min : 0.974146842956543, max : 0.9992503523826599\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.7401752471923828, std : 0.0526374988257885, min : 0.5535315275192261, max : 0.9175042510032654\n",
      "Bert mean : 0.9831719994544983, std : 0.021602369844913483, min : 0.837393581867218, max : 0.9999088048934937\n",
      "Roberta mean : 0.9946381449699402, std : 0.003148648189380765, min : 0.9719949960708618, max : 0.9991382360458374\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.6754191517829895, std : 0.05786080285906792, min : 0.478171169757843, max : 0.9094796776771545\n",
      "Bert mean : 0.9794750809669495, std : 0.024401560425758362, min : 0.8290318846702576, max : 0.9999397993087769\n",
      "Roberta mean : 0.9949482083320618, std : 0.0031231106258928776, min : 0.9692689180374146, max : 0.9991844892501831\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.7053120732307434, std : 0.05644126236438751, min : 0.495100200176239, max : 0.946507453918457\n",
      "Bert mean : 0.9834745526313782, std : 0.019917452707886696, min : 0.8337711095809937, max : 0.9999627470970154\n",
      "Roberta mean : 0.995231032371521, std : 0.00270122941583395, min : 0.9763767719268799, max : 0.9991820454597473\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.7074174284934998, std : 0.05751640349626541, min : 0.518134355545044, max : 0.9045288562774658\n",
      "Bert mean : 0.9807239174842834, std : 0.023474255576729774, min : 0.829436182975769, max : 0.9999704957008362\n",
      "Roberta mean : 0.9953163266181946, std : 0.0028329852502793074, min : 0.9700811505317688, max : 0.9992713332176208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_dict = {i : {'lama' : [],\n",
    "                  'bert' : [],\n",
    "                'roberta' : [] } for i in range(6)}\n",
    "cnt = 0\n",
    "for data in test_data:\n",
    "    cnt += 1\n",
    "    l_rep, b_rep, r_rep, label = data\n",
    "    l_rep = l_rep.squeeze()\n",
    "    b_rep = b_rep.squeeze()\n",
    "    r_rep = r_rep.squeeze()\n",
    "    label = label.item()\n",
    "    reps_dict[label]['lama'].append(l_rep)\n",
    "    reps_dict[label]['bert'].append(b_rep)\n",
    "    reps_dict[label]['roberta'].append(r_rep)\n",
    "cnt == len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dict = {i : {j :{'lama' : [] ,'bert': [],'roberta': []}  for j in range(6) if i != j } for i in range(6)}\n",
    "for i in range(6):\n",
    "    # lama, bert, roberta 각각의 평균 코사인 유사도 구하기\n",
    "\n",
    "    for j in range(6):\n",
    "        lama_cosine = []\n",
    "        bert_cosine = []\n",
    "        roberta_cosine = []\n",
    "        if i != j :\n",
    "            for l in range(len(reps_dict[i]['lama'])):\n",
    "                for m in range(len(reps_dict[j]['lama'])):\n",
    "                    lama_cosine.append(get_cosine_similarity(reps_dict[i]['lama'][l].flatten() , reps_dict[j]['lama'][m].flatten()).item())\n",
    "                    bert_cosine.append(get_cosine_similarity(reps_dict[i]['bert'][l].flatten() , reps_dict[j]['bert'][m].flatten()).item())\n",
    "                    roberta_cosine.append(get_cosine_similarity(reps_dict[i]['roberta'][l].flatten() , reps_dict[j]['roberta'][m].flatten()).item())\n",
    "            \n",
    "            all_dict[i][j]['lama'] = torch.tensor(lama_cosine)\n",
    "            all_dict[i][j]['bert'] = torch.tensor(bert_cosine)\n",
    "            all_dict[i][j]['roberta'] = torch.tensor(roberta_cosine)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 - Label 1 :\n",
      "Lama mean : 0.6727877855300903, std : 0.05061781033873558, min : 0.5362988710403442, max : 0.8274257183074951\n",
      "Bert mean : 0.9854336977005005, std : 0.01720646768808365, min : 0.9064790606498718, max : 0.9998049736022949\n",
      "Roberta mean : 0.9939550757408142, std : 0.003750670701265335, min : 0.9695395827293396, max : 0.9986449480056763\n",
      "\n",
      "Label 0 - Label 2 :\n",
      "Lama mean : 0.6256682872772217, std : 0.04690054431557655, min : 0.5026456713676453, max : 0.7708511352539062\n",
      "Bert mean : 0.9785114526748657, std : 0.023559190332889557, min : 0.8749093413352966, max : 0.999830424785614\n",
      "Roberta mean : 0.9937593936920166, std : 0.0033980885054916143, min : 0.9778833389282227, max : 0.9988173842430115\n",
      "\n",
      "Label 0 - Label 3 :\n",
      "Lama mean : 0.7160433530807495, std : 0.06317172944545746, min : 0.48789769411087036, max : 0.8927400708198547\n",
      "Bert mean : 0.9812770485877991, std : 0.021685641258955002, min : 0.8784774541854858, max : 0.9998173117637634\n",
      "Roberta mean : 0.9943814873695374, std : 0.0028462272603064775, min : 0.9811992049217224, max : 0.9991781711578369\n",
      "\n",
      "Label 0 - Label 4 :\n",
      "Lama mean : 0.6817430257797241, std : 0.05502455681562424, min : 0.506808340549469, max : 0.8944714665412903\n",
      "Bert mean : 0.97779780626297, std : 0.02531265653669834, min : 0.8712374567985535, max : 0.9998878240585327\n",
      "Roberta mean : 0.9944855570793152, std : 0.002795423613861203, min : 0.9821984171867371, max : 0.9991461038589478\n",
      "\n",
      "Label 0 - Label 5 :\n",
      "Lama mean : 0.7502748370170593, std : 0.04956452548503876, min : 0.5820572376251221, max : 0.8712494969367981\n",
      "Bert mean : 0.9759315848350525, std : 0.026673534885048866, min : 0.8731300234794617, max : 0.9998658895492554\n",
      "Roberta mean : 0.9946355223655701, std : 0.002596417209133506, min : 0.982982337474823, max : 0.998644232749939\n",
      "\n",
      "Label 1 - Label 0 :\n",
      "Lama mean : 0.6727878451347351, std : 0.05061781033873558, min : 0.5362988710403442, max : 0.8274257183074951\n",
      "Bert mean : 0.98543381690979, std : 0.01720646768808365, min : 0.9064790606498718, max : 0.9998049736022949\n",
      "Roberta mean : 0.9939550757408142, std : 0.003750670701265335, min : 0.9695395827293396, max : 0.9986449480056763\n",
      "\n",
      "Label 1 - Label 2 :\n",
      "Lama mean : 0.7148640155792236, std : 0.06630896031856537, min : 0.5661444067955017, max : 0.8951765894889832\n",
      "Bert mean : 0.9836869835853577, std : 0.016397597268223763, min : 0.9193012714385986, max : 0.9997873306274414\n",
      "Roberta mean : 0.9937429428100586, std : 0.0041302647441625595, min : 0.9644387364387512, max : 0.998778223991394\n",
      "\n",
      "Label 1 - Label 3 :\n",
      "Lama mean : 0.6503151059150696, std : 0.07053184509277344, min : 0.46203088760375977, max : 0.8612426519393921\n",
      "Bert mean : 0.9872787594795227, std : 0.013720164075493813, min : 0.9248362183570862, max : 0.9998303651809692\n",
      "Roberta mean : 0.9945135712623596, std : 0.0033400668762624264, min : 0.9766751527786255, max : 0.9987953901290894\n",
      "\n",
      "Label 1 - Label 4 :\n",
      "Lama mean : 0.653721809387207, std : 0.063082255423069, min : 0.5266755819320679, max : 0.8380176424980164\n",
      "Bert mean : 0.9841026663780212, std : 0.015989765524864197, min : 0.9184595346450806, max : 0.9998691082000732\n",
      "Roberta mean : 0.9946354031562805, std : 0.0036339201033115387, min : 0.96739661693573, max : 0.9986235499382019\n",
      "\n",
      "Label 1 - Label 5 :\n",
      "Lama mean : 0.7402839064598083, std : 0.05671558529138565, min : 0.6014279127120972, max : 0.8973844647407532\n",
      "Bert mean : 0.9810793399810791, std : 0.019610842689871788, min : 0.906024694442749, max : 0.9998379945755005\n",
      "Roberta mean : 0.9947232604026794, std : 0.003249021712690592, min : 0.9778653979301453, max : 0.9985402822494507\n",
      "\n",
      "Label 2 - Label 0 :\n",
      "Lama mean : 0.6256683468818665, std : 0.04690054431557655, min : 0.5026456713676453, max : 0.7708511352539062\n",
      "Bert mean : 0.9785114526748657, std : 0.023559190332889557, min : 0.8749093413352966, max : 0.999830424785614\n",
      "Roberta mean : 0.9937593936920166, std : 0.0033980885054916143, min : 0.9778833389282227, max : 0.9988173842430115\n",
      "\n",
      "Label 2 - Label 1 :\n",
      "Lama mean : 0.7148640155792236, std : 0.06630896031856537, min : 0.5661444067955017, max : 0.8951765894889832\n",
      "Bert mean : 0.9836868643760681, std : 0.016397597268223763, min : 0.9193012714385986, max : 0.9997873306274414\n",
      "Roberta mean : 0.9937430620193481, std : 0.0041302647441625595, min : 0.9644387364387512, max : 0.998778223991394\n",
      "\n",
      "Label 2 - Label 3 :\n",
      "Lama mean : 0.6691842079162598, std : 0.0680985301733017, min : 0.4621981978416443, max : 0.8537076115608215\n",
      "Bert mean : 0.9797020554542542, std : 0.021568983793258667, min : 0.8920875787734985, max : 0.9999377131462097\n",
      "Roberta mean : 0.9942718744277954, std : 0.003319636918604374, min : 0.9775134325027466, max : 0.9986808896064758\n",
      "\n",
      "Label 2 - Label 4 :\n",
      "Lama mean : 0.70567786693573, std : 0.058600056916475296, min : 0.5493291020393372, max : 0.8657492995262146\n",
      "Bert mean : 0.9762131571769714, std : 0.02524852193892002, min : 0.8848755955696106, max : 0.9999403953552246\n",
      "Roberta mean : 0.9944411516189575, std : 0.0034593837335705757, min : 0.9757620692253113, max : 0.9988154172897339\n",
      "\n",
      "Label 2 - Label 5 :\n",
      "Lama mean : 0.6962196230888367, std : 0.06525536626577377, min : 0.5340803861618042, max : 0.8906973600387573\n",
      "Bert mean : 0.9744121432304382, std : 0.02748067118227482, min : 0.8747442960739136, max : 0.9999223947525024\n",
      "Roberta mean : 0.9944242835044861, std : 0.003201760584488511, min : 0.9792300462722778, max : 0.9988391995429993\n",
      "\n",
      "Label 3 - Label 0 :\n",
      "Lama mean : 0.7160434126853943, std : 0.06317172944545746, min : 0.48789769411087036, max : 0.8927400708198547\n",
      "Bert mean : 0.9812771677970886, std : 0.021685641258955002, min : 0.8784774541854858, max : 0.9998173117637634\n",
      "Roberta mean : 0.9943816065788269, std : 0.0028462272603064775, min : 0.9811992049217224, max : 0.9991781711578369\n",
      "\n",
      "Label 3 - Label 1 :\n",
      "Lama mean : 0.6503150463104248, std : 0.07053184509277344, min : 0.46203088760375977, max : 0.8612426519393921\n",
      "Bert mean : 0.9872786402702332, std : 0.013720164075493813, min : 0.9248362183570862, max : 0.9998303651809692\n",
      "Roberta mean : 0.9945135712623596, std : 0.0033400668762624264, min : 0.9766751527786255, max : 0.9987953901290894\n",
      "\n",
      "Label 3 - Label 2 :\n",
      "Lama mean : 0.669184148311615, std : 0.0680985301733017, min : 0.4621981978416443, max : 0.8537076115608215\n",
      "Bert mean : 0.9797020554542542, std : 0.021568983793258667, min : 0.8920875787734985, max : 0.9999377131462097\n",
      "Roberta mean : 0.9942720532417297, std : 0.003319636918604374, min : 0.9775134325027466, max : 0.9986808896064758\n",
      "\n",
      "Label 3 - Label 4 :\n",
      "Lama mean : 0.7484471797943115, std : 0.05855855718255043, min : 0.5452035069465637, max : 0.9061942100524902\n",
      "Bert mean : 0.9816817045211792, std : 0.019948618486523628, min : 0.9146487712860107, max : 0.999924898147583\n",
      "Roberta mean : 0.9953834414482117, std : 0.0026863429229706526, min : 0.9805960059165955, max : 0.9989043474197388\n",
      "\n",
      "Label 3 - Label 5 :\n",
      "Lama mean : 0.7279052138328552, std : 0.06363210082054138, min : 0.540913999080658, max : 0.9076494574546814\n",
      "Bert mean : 0.9776068925857544, std : 0.024495601654052734, min : 0.8781192898750305, max : 0.9999323487281799\n",
      "Roberta mean : 0.9953649640083313, std : 0.0021433045621961355, min : 0.9871366620063782, max : 0.9987760782241821\n",
      "\n",
      "Label 4 - Label 0 :\n",
      "Lama mean : 0.6817430257797241, std : 0.05502455681562424, min : 0.506808340549469, max : 0.8944714665412903\n",
      "Bert mean : 0.9777979254722595, std : 0.02531265653669834, min : 0.8712374567985535, max : 0.9998878240585327\n",
      "Roberta mean : 0.9944854974746704, std : 0.002795423613861203, min : 0.9821984171867371, max : 0.9991461038589478\n",
      "\n",
      "Label 4 - Label 1 :\n",
      "Lama mean : 0.653721809387207, std : 0.063082255423069, min : 0.5266755819320679, max : 0.8380176424980164\n",
      "Bert mean : 0.9841026663780212, std : 0.015989765524864197, min : 0.9184595346450806, max : 0.9998691082000732\n",
      "Roberta mean : 0.9946354031562805, std : 0.0036339201033115387, min : 0.96739661693573, max : 0.9986235499382019\n",
      "\n",
      "Label 4 - Label 2 :\n",
      "Lama mean : 0.7056779265403748, std : 0.058600056916475296, min : 0.5493291020393372, max : 0.8657492995262146\n",
      "Bert mean : 0.976213276386261, std : 0.02524852193892002, min : 0.8848755955696106, max : 0.9999403953552246\n",
      "Roberta mean : 0.994441032409668, std : 0.0034593837335705757, min : 0.9757620692253113, max : 0.9988154172897339\n",
      "\n",
      "Label 4 - Label 3 :\n",
      "Lama mean : 0.7484471797943115, std : 0.05855855718255043, min : 0.5452035069465637, max : 0.9061942100524902\n",
      "Bert mean : 0.9816817045211792, std : 0.019948618486523628, min : 0.9146487712860107, max : 0.999924898147583\n",
      "Roberta mean : 0.9953834414482117, std : 0.0026863429229706526, min : 0.9805960059165955, max : 0.9989043474197388\n",
      "\n",
      "Label 4 - Label 5 :\n",
      "Lama mean : 0.7230647802352905, std : 0.06412310898303986, min : 0.5844976305961609, max : 0.8759551048278809\n",
      "Bert mean : 0.9749372601509094, std : 0.028126247227191925, min : 0.8709779977798462, max : 0.9999578595161438\n",
      "Roberta mean : 0.9957727193832397, std : 0.002352908719331026, min : 0.9825828671455383, max : 0.998999297618866\n",
      "\n",
      "Label 5 - Label 0 :\n",
      "Lama mean : 0.7502748966217041, std : 0.04956452548503876, min : 0.5820572376251221, max : 0.8712494969367981\n",
      "Bert mean : 0.9759316444396973, std : 0.026673534885048866, min : 0.8731300234794617, max : 0.9998658895492554\n",
      "Roberta mean : 0.9946355819702148, std : 0.002596417209133506, min : 0.982982337474823, max : 0.998644232749939\n",
      "\n",
      "Label 5 - Label 1 :\n",
      "Lama mean : 0.7402837872505188, std : 0.05671558529138565, min : 0.6014279127120972, max : 0.8973844647407532\n",
      "Bert mean : 0.9810793399810791, std : 0.019610842689871788, min : 0.906024694442749, max : 0.9998379945755005\n",
      "Roberta mean : 0.9947232604026794, std : 0.003249021712690592, min : 0.9778653979301453, max : 0.9985402822494507\n",
      "\n",
      "Label 5 - Label 2 :\n",
      "Lama mean : 0.6962196230888367, std : 0.06525536626577377, min : 0.5340803861618042, max : 0.8906973600387573\n",
      "Bert mean : 0.9744120240211487, std : 0.02748067118227482, min : 0.8747442960739136, max : 0.9999223947525024\n",
      "Roberta mean : 0.9944244027137756, std : 0.003201760584488511, min : 0.9792300462722778, max : 0.9988391995429993\n",
      "\n",
      "Label 5 - Label 3 :\n",
      "Lama mean : 0.7279052734375, std : 0.06363210082054138, min : 0.540913999080658, max : 0.9076494574546814\n",
      "Bert mean : 0.9776069521903992, std : 0.024495601654052734, min : 0.8781192898750305, max : 0.9999323487281799\n",
      "Roberta mean : 0.9953649640083313, std : 0.0021433045621961355, min : 0.9871366620063782, max : 0.9987760782241821\n",
      "\n",
      "Label 5 - Label 4 :\n",
      "Lama mean : 0.7230648398399353, std : 0.06412310898303986, min : 0.5844976305961609, max : 0.8759551048278809\n",
      "Bert mean : 0.9749372601509094, std : 0.028126247227191925, min : 0.8709779977798462, max : 0.9999578595161438\n",
      "Roberta mean : 0.9957727193832397, std : 0.002352908719331026, min : 0.9825828671455383, max : 0.998999297618866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# i, j 레이블 간의 평균 코사인 유사도 구하기\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        if i != j:\n",
    "            print(f'Label {i} - Label {j} :')\n",
    "            print(f'Lama mean : {all_dict[i][j][\"lama\"].mean()}, std : {all_dict[i][j][\"lama\"].std()}, min : {all_dict[i][j][\"lama\"].min()}, max : {all_dict[i][j][\"lama\"].max()}')\n",
    "            print(f'Bert mean : {all_dict[i][j][\"bert\"].mean()}, std : {all_dict[i][j][\"bert\"].std()}, min : {all_dict[i][j][\"bert\"].min()}, max : {all_dict[i][j][\"bert\"].max()}')\n",
    "            print(f'Roberta mean : {all_dict[i][j][\"roberta\"].mean()}, std : {all_dict[i][j][\"roberta\"].std()}, min : {all_dict[i][j][\"roberta\"].min()}, max : {all_dict[i][j][\"roberta\"].max()}')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
